2025-10-17 03:00:11,190 INFO [LIST] Using proxy: None
2025-10-17 03:00:11,197 ERROR [LIST] Error scraping https://www.amazon.com/bestsellers: 
2025-10-17 03:00:16,261 ERROR Future exception was never retrieved
future: <Future finished exception=NotImplementedError()>
Traceback (most recent call last):
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 37, in scrape_amazon
    with sync_playwright() as p:
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\sync_api\_context_manager.py", line 77, in __enter__
    dispatcher_fiber.switch()
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\sync_api\_context_manager.py", line 56, in greenlet_main
    self._loop.run_until_complete(self._connection.run_as_sync())
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\_impl\_connection.py", line 301, in run_as_sync
    await self.run()
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\_impl\_connection.py", line 310, in run
    await self._transport.connect()
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\_impl\_transport.py", line 133, in connect
    raise exc
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\_impl\_transport.py", line 120, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\subprocess.py", line 223, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 1708, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 503, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError
2025-10-17 03:22:41,903 INFO [INIT] URL=https://www.amazon.com/bestsellers proxy=None ua=Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1
2025-10-17 03:22:41,909 ERROR [EXCEPTION] scrape_amazonÊ§°Ü: 
2025-10-17 03:22:41,980 ERROR Future exception was never retrieved
future: <Future finished exception=NotImplementedError()>
Traceback (most recent call last):
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 59, in scrape_amazon
    html = _load_page(url, proxy, ua, headless)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 110, in _load_page
    with sync_playwright() as p:
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\sync_api\_context_manager.py", line 77, in __enter__
    dispatcher_fiber.switch()
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\sync_api\_context_manager.py", line 56, in greenlet_main
    self._loop.run_until_complete(self._connection.run_as_sync())
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\_impl\_connection.py", line 301, in run_as_sync
    await self.run()
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\_impl\_connection.py", line 310, in run
    await self._transport.connect()
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\_impl\_transport.py", line 133, in connect
    raise exc
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\site-packages\playwright\_impl\_transport.py", line 120, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\subprocess.py", line 223, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 1708, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 503, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError
2025-10-17 03:48:51,188 INFO [INIT] URL=https://www.amazon.com/bestsellers proxy=None ua=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15 scraped=0
2025-10-17 03:48:51,192 ERROR [EXCEPTION] scrape_amazonÊ§°Ü: type=<class 'NotImplementedError'> repr=NotImplementedError()
2025-10-17 03:48:51,198 ERROR Traceback (most recent call last):
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 88, in scrape_amazon
    html = _load_page(url, proxy, ua, headless)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 137, in _load_page
    with sync_playwright() as p:
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\sync_api\_context_manager.py", line 77, in __enter__
    dispatcher_fiber.switch()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\sync_api\_context_manager.py", line 56, in greenlet_main
    self._loop.run_until_complete(self._connection.run_as_sync())
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 301, in run_as_sync
    await self.run()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 310, in run
    await self._transport.connect()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_transport.py", line 133, in connect
    raise exc
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_transport.py", line 120, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\subprocess.py", line 223, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 1708, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 503, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError

2025-10-17 03:48:51,273 ERROR Future exception was never retrieved
future: <Future finished exception=NotImplementedError()>
Traceback (most recent call last):
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 88, in scrape_amazon
    html = _load_page(url, proxy, ua, headless)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 137, in _load_page
    with sync_playwright() as p:
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\sync_api\_context_manager.py", line 77, in __enter__
    dispatcher_fiber.switch()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\sync_api\_context_manager.py", line 56, in greenlet_main
    self._loop.run_until_complete(self._connection.run_as_sync())
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 301, in run_as_sync
    await self.run()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 310, in run
    await self._transport.connect()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_transport.py", line 133, in connect
    raise exc
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_transport.py", line 120, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\subprocess.py", line 223, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 1708, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 503, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError
2025-10-17 03:57:31,536 INFO [INIT] URL=https://www.amazon.com/bestsellers proxy=None ua=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 scraped=0
2025-10-17 03:57:31,540 ERROR [EXCEPTION] scrape_amazonÊ§°Ü: type=<class 'NotImplementedError'> repr=NotImplementedError()
2025-10-17 03:57:31,544 ERROR Traceback (most recent call last):
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 88, in scrape_amazon
    html = _load_page(url, proxy, ua, headless)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 137, in _load_page
    with sync_playwright() as p:
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\sync_api\_context_manager.py", line 77, in __enter__
    dispatcher_fiber.switch()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\sync_api\_context_manager.py", line 56, in greenlet_main
    self._loop.run_until_complete(self._connection.run_as_sync())
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 301, in run_as_sync
    await self.run()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 310, in run
    await self._transport.connect()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_transport.py", line 133, in connect
    raise exc
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_transport.py", line 120, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\subprocess.py", line 223, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 1708, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 503, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError

2025-10-17 03:57:31,597 ERROR Future exception was never retrieved
future: <Future finished exception=NotImplementedError()>
Traceback (most recent call last):
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 88, in scrape_amazon
    html = _load_page(url, proxy, ua, headless)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\scrapers\amazon_scraper.py", line 137, in _load_page
    with sync_playwright() as p:
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\sync_api\_context_manager.py", line 77, in __enter__
    dispatcher_fiber.switch()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\sync_api\_context_manager.py", line 56, in greenlet_main
    self._loop.run_until_complete(self._connection.run_as_sync())
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 301, in run_as_sync
    await self.run()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_connection.py", line 310, in run
    await self._transport.connect()
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_transport.py", line 133, in connect
    raise exc
  File "D:\ÖÇÄÜÌå\D¾©Ê¢´«Ã½ÖÇÄÜÌå_ÆóÒµ°æ\.venv\Lib\site-packages\playwright\_impl\_transport.py", line 120, in connect
    self._proc = await asyncio.create_subprocess_exec(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\subprocess.py", line 223, in create_subprocess_exec
    transport, protocol = await loop.subprocess_exec(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 1708, in subprocess_exec
    transport = await self._make_subprocess_transport(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\29270\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 503, in _make_subprocess_transport
    raise NotImplementedError
NotImplementedError
2025-10-17 17:45:50,403 - scrapers - INFO - æ•°æ®å·²ä¿å­˜ / Data saved: data/amazon/example_products.json
2025-10-17 17:48:28,480 - scrapers - INFO - æ•°æ®å·²ä¿å­˜ / Data saved: data/amazon/example_products.json
2025-10-17 17:52:36,607 - scrapers - INFO - æ•°æ®å·²ä¿å­˜ / Data saved: data/amazon/example_products.json
2025-10-17 19:13:08,867 - scrapers - INFO - [tiktokshop] æ•°æ®å·²ä¿å­˜ / Data saved: data/tiktokshop/example_tiktokshop.json
2025-10-17 19:16:55,616 - scrapers - INFO - [tiktokshop] æ•°æ®å·²ä¿å­˜ / Data saved: data/tiktokshop/example_tiktokshop.json
2025-10-17 19:20:38,790 - scrapers - INFO - [tiktokshop] æ•°æ®å·²ä¿å­˜ / Data saved: data/tiktokshop/example_tiktokshop.json
2025-10-17 19:40:18,751 - scrapers - INFO - è­¦æŠ¥é˜ˆå€¼å·²æ›´æ–°: error_rate = 0.3
2025-10-17 22:30:56,424 - core.smart_analysis - WARNING - OPENAI_API_KEY not configured
2025-10-19 04:23:01,176 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:23:01,180 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:23:01,180 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:23:01,181 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:23:01,182 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:23:01,183 - apscheduler.scheduler - INFO - Added job "job_collect" to job store "default"
2025-10-19 04:23:01,183 - apscheduler.scheduler - INFO - Added job "job_daily_report" to job store "default"
2025-10-19 04:23:01,183 - apscheduler.scheduler - INFO - Added job "job_evolution_check" to job store "default"
2025-10-19 04:23:01,184 - apscheduler.scheduler - INFO - Added job "job_self_learn" to job store "default"
2025-10-19 04:23:01,184 - apscheduler.scheduler - INFO - Added job "job_self_learn" to job store "default"
2025-10-19 04:23:01,184 - apscheduler.scheduler - INFO - Scheduler started
2025-10-19 04:23:01,185 - scrapers - INFO - [Scheduler] å·²å¯åŠ¨
2025-10-19 04:23:32,459 - scrapers - INFO - å¼€å§‹é‡‡é›†åˆ—è¡¨é¡µ / Starting list page scraping: https://www.amazon.com/bestsellers
2025-10-19 04:23:32,460 - scrapers - INFO - æ­£åœ¨è·å–é¡µé¢ / Fetching page: https://www.amazon.com/bestsellers
2025-10-19 04:23:34,987 - scrapers - INFO - [LIST_TIME] secs=2.53
2025-10-19 04:23:35,151 - scrapers - INFO - ä½¿ç”¨é€‰æ‹©å™¨æ‰¾åˆ° 36 ä¸ªå•†å“ / Found 36 items with selector: div.p13n-sc-uncoverable-faceout
2025-10-19 04:23:35,151 - scrapers - INFO - åˆ—è¡¨é¡µé‡‡é›†å®Œæˆï¼Œå…± 0 ä¸ªå•†å“ / List page scraping completed, 0 products
2025-10-19 04:23:35,151 - scrapers - WARNING - é›¶ç»“æœé¡µé¢ / Zero result page: https://www.amazon.com/bestsellers
2025-10-19 04:30:17,406 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:30:17,410 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:30:17,410 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:30:17,411 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:30:17,411 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:30:17,412 - apscheduler.scheduler - INFO - Added job "job_collect" to job store "default"
2025-10-19 04:30:17,413 - apscheduler.scheduler - INFO - Added job "job_daily_report" to job store "default"
2025-10-19 04:30:17,413 - apscheduler.scheduler - INFO - Added job "job_evolution_check" to job store "default"
2025-10-19 04:30:17,413 - apscheduler.scheduler - INFO - Added job "job_self_learn" to job store "default"
2025-10-19 04:30:17,413 - apscheduler.scheduler - INFO - Added job "job_self_learn" to job store "default"
2025-10-19 04:30:17,415 - apscheduler.scheduler - INFO - Scheduler started
2025-10-19 04:30:17,416 - scrapers - INFO - [Scheduler] å·²å¯åŠ¨
2025-10-19 04:30:25,200 - scrapers - INFO - å¼€å§‹é‡‡é›†åˆ—è¡¨é¡µ / Starting list page scraping: https://www.amazon.com/bestsellers
2025-10-19 04:30:25,200 - scrapers - INFO - æ­£åœ¨è·å–é¡µé¢ / Fetching page: https://www.amazon.com/bestsellers
2025-10-19 04:30:27,595 - scrapers - INFO - [LIST_TIME] secs=2.40
2025-10-19 04:30:27,697 - scrapers - INFO - ä½¿ç”¨é€‰æ‹©å™¨æ‰¾åˆ° 36 ä¸ªå•†å“ / Found 36 items with selector: div.p13n-sc-uncoverable-faceout
2025-10-19 04:30:27,698 - scrapers - INFO - åˆ—è¡¨é¡µé‡‡é›†å®Œæˆï¼Œå…± 0 ä¸ªå•†å“ / List page scraping completed, 0 products
2025-10-19 04:30:27,698 - scrapers - WARNING - é›¶ç»“æœé¡µé¢ / Zero result page: https://www.amazon.com/bestsellers
2025-10-19 04:30:37,591 - scrapers - INFO - å¼€å§‹é‡‡é›†åˆ—è¡¨é¡µ / Starting list page scraping: https://www.amazon.com/bestsellers
2025-10-19 04:30:37,592 - scrapers - INFO - æ­£åœ¨è·å–é¡µé¢ / Fetching page: https://www.amazon.com/bestsellers
2025-10-19 04:30:40,037 - scrapers - INFO - [LIST_TIME] secs=2.45
2025-10-19 04:30:40,145 - scrapers - INFO - ä½¿ç”¨é€‰æ‹©å™¨æ‰¾åˆ° 36 ä¸ªå•†å“ / Found 36 items with selector: div.p13n-sc-uncoverable-faceout
2025-10-19 04:30:40,147 - scrapers - INFO - åˆ—è¡¨é¡µé‡‡é›†å®Œæˆï¼Œå…± 0 ä¸ªå•†å“ / List page scraping completed, 0 products
2025-10-19 04:30:40,147 - scrapers - WARNING - é›¶ç»“æœé¡µé¢ / Zero result page: https://www.amazon.com/bestsellers
2025-10-19 04:34:39,679 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 04:35:02,160 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 04:35:06,510 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 04:35:09,027 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 04:35:09,987 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 04:35:13,990 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 04:35:17,441 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 04:46:14,807 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:46:14,811 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:46:14,811 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:46:14,812 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:46:14,812 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 04:46:14,814 - apscheduler.scheduler - INFO - Added job "job_collect" to job store "default"
2025-10-19 04:46:14,814 - apscheduler.scheduler - INFO - Added job "job_daily_report" to job store "default"
2025-10-19 04:46:14,814 - apscheduler.scheduler - INFO - Added job "job_evolution_check" to job store "default"
2025-10-19 04:46:14,814 - apscheduler.scheduler - INFO - Added job "job_self_learn" to job store "default"
2025-10-19 04:46:14,814 - apscheduler.scheduler - INFO - Added job "job_self_learn" to job store "default"
2025-10-19 04:46:14,815 - apscheduler.scheduler - INFO - Scheduler started
2025-10-19 04:46:14,816 - scrapers - INFO - [Scheduler] å·²å¯åŠ¨
2025-10-19 04:46:25,694 - scrapers - INFO - å¼€å§‹é‡‡é›†åˆ—è¡¨é¡µ / Starting list page scraping: https://www.amazon.com/bestsellers
2025-10-19 04:46:25,694 - scrapers - INFO - æ­£åœ¨è·å–é¡µé¢ / Fetching page: https://www.amazon.com/bestsellers
2025-10-19 04:46:28,152 - scrapers - INFO - [LIST_TIME] secs=2.46
2025-10-19 04:46:28,274 - scrapers - INFO - ä½¿ç”¨é€‰æ‹©å™¨æ‰¾åˆ° 36 ä¸ªå•†å“ / Found 36 items with selector: div.p13n-sc-uncoverable-faceout
2025-10-19 04:46:28,274 - scrapers - INFO - åˆ—è¡¨é¡µé‡‡é›†å®Œæˆï¼Œå…± 0 ä¸ªå•†å“ / List page scraping completed, 0 products
2025-10-19 04:46:28,275 - scrapers - WARNING - é›¶ç»“æœé¡µé¢ / Zero result page: https://www.amazon.com/bestsellers
2025-10-19 04:51:46,065 - scrapers - INFO - å¼€å§‹é‡‡é›†åˆ—è¡¨é¡µ / Starting list page scraping: https://www.amazon.com/bestsellers
2025-10-19 04:51:46,066 - scrapers - INFO - æ­£åœ¨è·å–é¡µé¢ / Fetching page: https://www.amazon.com/bestsellers
2025-10-19 04:51:47,251 - scrapers - INFO - [LIST_TIME] secs=1.18
2025-10-19 04:51:47,252 - scrapers - ERROR - [ERROR] è¯·æ±‚å¤±è´¥ / Request failed: https://www.amazon.com/bestsellers - 429 Client Error: Too Many Requests for url: https://www.amazon.com/bestsellers
2025-10-19 04:51:48,860 - scrapers - INFO - æ­£åœ¨è·å–é¡µé¢ / Fetching page: https://www.amazon.com/bestsellers
2025-10-19 04:51:50,129 - scrapers - INFO - [LIST_TIME] secs=1.27
2025-10-19 04:51:50,224 - scrapers - INFO - ä½¿ç”¨é€‰æ‹©å™¨æ‰¾åˆ° 36 ä¸ªå•†å“ / Found 36 items with selector: div.p13n-sc-uncoverable-faceout
2025-10-19 04:51:50,225 - scrapers - INFO - åˆ—è¡¨é¡µé‡‡é›†å®Œæˆï¼Œå…± 0 ä¸ªå•†å“ / List page scraping completed, 0 products
2025-10-19 04:51:50,225 - scrapers - WARNING - é›¶ç»“æœé¡µé¢ / Zero result page: https://www.amazon.com/bestsellers
2025-10-19 05:30:17,439 - apscheduler.executors.default - INFO - Running job "job_collect (trigger: interval[1:00:00], next run at: 2025-10-19 05:30:17 CST)" (scheduled at 2025-10-19 05:30:17.406238+08:00)
2025-10-19 05:30:17,439 - scrapers - INFO - [Job] é‡‡é›†å¸‚åœºæƒå¨æ•°æ®
2025-10-19 05:30:17,439 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 05:30:17,440 - scrapers - INFO - [Job] Trends count=6
2025-10-19 05:30:17,440 - apscheduler.executors.default - INFO - Job "job_collect (trigger: interval[1:00:00], next run at: 2025-10-19 06:30:17 CST)" executed successfully
2025-10-19 05:46:14,833 - apscheduler.executors.default - INFO - Running job "job_collect (trigger: interval[1:00:00], next run at: 2025-10-19 05:46:14 CST)" (scheduled at 2025-10-19 05:46:14.807383+08:00)
2025-10-19 05:46:14,834 - scrapers - INFO - [Job] é‡‡é›†å¸‚åœºæƒå¨æ•°æ®
2025-10-19 05:46:14,834 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 05:46:14,834 - scrapers - INFO - [Job] Trends count=6
2025-10-19 05:46:14,835 - apscheduler.executors.default - INFO - Job "job_collect (trigger: interval[1:00:00], next run at: 2025-10-19 06:46:14 CST)" executed successfully
2025-10-19 05:50:57,443 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 05:50:57,450 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 05:50:57,450 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 05:50:57,451 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 05:50:57,451 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-10-19 05:50:57,455 - apscheduler.scheduler - INFO - Added job "job_collect" to job store "default"
2025-10-19 05:50:57,456 - apscheduler.scheduler - INFO - Added job "job_daily_report" to job store "default"
2025-10-19 05:50:57,456 - apscheduler.scheduler - INFO - Added job "job_evolution_check" to job store "default"
2025-10-19 05:50:57,457 - apscheduler.scheduler - INFO - Added job "job_self_learn" to job store "default"
2025-10-19 05:50:57,457 - apscheduler.scheduler - INFO - Added job "job_self_learn" to job store "default"
2025-10-19 05:50:57,458 - apscheduler.scheduler - INFO - Scheduler started
2025-10-19 05:50:57,459 - scrapers - INFO - [Scheduler] å·²å¯åŠ¨
2025-10-19 06:30:17,429 - apscheduler.executors.default - INFO - Running job "job_collect (trigger: interval[1:00:00], next run at: 2025-10-19 07:30:17 CST)" (scheduled at 2025-10-19 06:30:17.406238+08:00)
2025-10-19 06:30:17,429 - apscheduler.executors.default - INFO - Running job "job_evolution_check (trigger: interval[2:00:00], next run at: 2025-10-19 08:30:17 CST)" (scheduled at 2025-10-19 06:30:17.410810+08:00)
2025-10-19 06:30:17,429 - scrapers - INFO - [Job] é‡‡é›†å¸‚åœºæƒå¨æ•°æ®
2025-10-19 06:30:17,429 - scrapers - INFO - [Job] è‡ªæˆ‘æ¼”åŒ–æ£€æŸ¥
2025-10-19 06:30:17,429 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 06:30:17,429 - scrapers - INFO - [Job] Trends count=6
2025-10-19 06:30:17,429 - scrapers - INFO - [Job] æ¼”åŒ–å»ºè®®å·²ç”Ÿæˆï¼Œè¡¥ä¸: None
2025-10-19 06:30:17,431 - apscheduler.executors.default - INFO - Job "job_collect (trigger: interval[1:00:00], next run at: 2025-10-19 07:30:17 CST)" executed successfully
2025-10-19 06:30:17,431 - apscheduler.executors.default - INFO - Job "job_evolution_check (trigger: interval[2:00:00], next run at: 2025-10-19 08:30:17 CST)" executed successfully
2025-10-19 06:50:57,476 - apscheduler.executors.default - INFO - Running job "job_collect (trigger: interval[1:00:00], next run at: 2025-10-19 06:50:57 CST)" (scheduled at 2025-10-19 06:50:57.442528+08:00)
2025-10-19 06:50:57,476 - scrapers - INFO - [Job] é‡‡é›†å¸‚åœºæƒå¨æ•°æ®
2025-10-19 06:50:57,477 - core.collectors.market_collector - INFO - Fetched 6 trend records from authoritative sources
2025-10-19 06:50:57,477 - scrapers - INFO - [Job] Trends count=6
2025-10-19 06:50:57,478 - apscheduler.executors.default - INFO - Job "job_collect (trigger: interval[1:00:00], next run at: 2025-10-19 07:50:57 CST)" executed successfully
2025-10-19 07:05:19,395 - scrapers - INFO - å¼€å§‹é‡‡é›†åˆ—è¡¨é¡µ / Starting list page scraping: https://www.amazon.com/bestsellers
2025-10-19 07:05:19,396 - scrapers - INFO - æ­£åœ¨è·å–é¡µé¢ / Fetching page: https://www.amazon.com/bestsellers
2025-10-19 07:05:20,687 - scrapers - INFO - [LIST_TIME] secs=1.29
2025-10-19 07:05:20,687 - scrapers - ERROR - [ERROR] è¯·æ±‚å¤±è´¥ / Request failed: https://www.amazon.com/bestsellers - 429 Client Error: Too Many Requests for url: https://www.amazon.com/bestsellers
2025-10-19 07:05:22,647 - scrapers - INFO - æ­£åœ¨è·å–é¡µé¢ / Fetching page: https://www.amazon.com/bestsellers
2025-10-19 07:05:24,017 - scrapers - INFO - [LIST_TIME] secs=1.37
2025-10-19 07:05:24,126 - scrapers - INFO - ä½¿ç”¨é€‰æ‹©å™¨æ‰¾åˆ° 36 ä¸ªå•†å“ / Found 36 items with selector: div.p13n-sc-uncoverable-faceout
2025-10-19 07:05:24,127 - scrapers - INFO - åˆ—è¡¨é¡µé‡‡é›†å®Œæˆï¼Œå…± 0 ä¸ªå•†å“ / List page scraping completed, 0 products
2025-10-19 07:05:24,127 - scrapers - WARNING - é›¶ç»“æœé¡µé¢ / Zero result page: https://www.amazon.com/bestsellers
2025-10-19 07:05:38,191 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-10-19 07:05:38,193 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-10-19 07:05:40,281 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-10-19 07:05:40,283 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
