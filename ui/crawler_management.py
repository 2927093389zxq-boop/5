"""
çˆ¬è™«ç®¡ç†ç•Œé¢ - é›†ä¸­ç®¡ç†æ‰€æœ‰çˆ¬è™«ä»£ç çš„UI
Crawler Management UI - Centralized UI for managing all crawler code
"""

import streamlit as st
from core.crawler_manager import CrawlerManager
from datetime import datetime
import json


def render_crawler_management():
    """æ¸²æŸ“çˆ¬è™«ç®¡ç†ç•Œé¢"""
    st.header("ğŸ•·ï¸ çˆ¬è™«ä»£ç ç®¡ç†ä¸­å¿ƒ")
    st.markdown("é›†ä¸­ç®¡ç†æ‰€æœ‰çˆ¬è™«ä»£ç ï¼Œæ”¯æŒä¾¿æ·æ·»åŠ ã€ç¼–è¾‘å’Œåˆ‡æ¢çˆ¬è™«")
    
    # åˆå§‹åŒ–çˆ¬è™«ç®¡ç†å™¨
    if 'crawler_manager' not in st.session_state:
        st.session_state.crawler_manager = CrawlerManager()
    
    manager = st.session_state.crawler_manager
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ çˆ¬è™«åˆ—è¡¨", "â• æ·»åŠ çˆ¬è™«", "ğŸ”§ ç¼–è¾‘çˆ¬è™«", "â–¶ï¸ æ‰§è¡Œçˆ¬è™«"])
    
    with tab1:
        render_crawler_list(manager)
    
    with tab2:
        render_add_crawler(manager)
    
    with tab3:
        render_edit_crawler(manager)
    
    with tab4:
        render_execute_crawler(manager)


def render_crawler_list(manager: CrawlerManager):
    """æ¸²æŸ“çˆ¬è™«åˆ—è¡¨"""
    st.markdown("### ğŸ“‹ å·²ä¿å­˜çš„çˆ¬è™«")
    
    # è¿‡æ»¤é€‰é¡¹
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        search = st.text_input("ğŸ” æœç´¢çˆ¬è™«", placeholder="è¾“å…¥åç§°æˆ–å¹³å°...")
    
    with col2:
        platform_filter = st.selectbox(
            "å¹³å°ç­›é€‰",
            ["å…¨éƒ¨"] + list(set([c.get('platform', 'custom') for c in manager.list_crawlers()]))
        )
    
    with col3:
        status_filter = st.selectbox("çŠ¶æ€ç­›é€‰", ["å…¨éƒ¨", "å·²å¯ç”¨", "å·²ç¦ç”¨"])
    
    # è·å–çˆ¬è™«åˆ—è¡¨
    crawlers = manager.list_crawlers()
    
    # åº”ç”¨è¿‡æ»¤
    if platform_filter != "å…¨éƒ¨":
        crawlers = [c for c in crawlers if c.get('platform') == platform_filter]
    
    if status_filter == "å·²å¯ç”¨":
        crawlers = [c for c in crawlers if c.get('enabled', True)]
    elif status_filter == "å·²ç¦ç”¨":
        crawlers = [c for c in crawlers if not c.get('enabled', True)]
    
    if search:
        crawlers = [
            c for c in crawlers
            if search.lower() in c.get('name', '').lower()
            or search.lower() in c.get('platform', '').lower()
        ]
    
    st.markdown("---")
    
    if not crawlers:
        st.info("æš‚æ— çˆ¬è™«ï¼Œè¯·åœ¨'æ·»åŠ çˆ¬è™«'æ ‡ç­¾é¡µä¸­æ·»åŠ ")
    else:
        # æ˜¾ç¤ºç»Ÿè®¡
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»æ•°", len(manager.list_crawlers()))
        with col2:
            enabled_count = len([c for c in manager.list_crawlers() if c.get('enabled', True)])
            st.metric("å·²å¯ç”¨", enabled_count)
        with col3:
            platforms_count = len(set([c.get('platform', 'custom') for c in manager.list_crawlers()]))
            st.metric("å¹³å°æ•°", platforms_count)
        
        st.markdown("---")
        
        # æ˜¾ç¤ºçˆ¬è™«åˆ—è¡¨
        for crawler in crawlers:
            with st.expander(
                f"ğŸ•·ï¸ {crawler.get('name', 'N/A')} - {crawler.get('platform', 'custom')}", 
                expanded=False
            ):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.markdown(f"**åç§°:** {crawler.get('name', 'N/A')}")
                    st.markdown(f"**å¹³å°:** {crawler.get('platform', 'custom')}")
                    st.markdown(f"**æè¿°:** {crawler.get('description', 'æ— æè¿°')}")
                    
                    status = "âœ… å·²å¯ç”¨" if crawler.get('enabled', True) else "âŒ å·²ç¦ç”¨"
                    st.markdown(f"**çŠ¶æ€:** {status}")
                    
                    created = crawler.get('created_at', 'N/A')[:19]
                    updated = crawler.get('updated_at', 'N/A')[:19]
                    st.caption(f"åˆ›å»ºæ—¶é—´: {created}")
                    st.caption(f"æ›´æ–°æ—¶é—´: {updated}")
                
                with col2:
                    # æ“ä½œæŒ‰é’®
                    if st.button("ğŸ‘ï¸ æŸ¥çœ‹ä»£ç ", key=f"view_{crawler['name']}", use_container_width=True):
                        st.session_state[f'viewing_code_{crawler["name"]}'] = True
                    
                    if crawler.get('enabled', True):
                        if st.button("ğŸš« ç¦ç”¨", key=f"disable_{crawler['name']}", use_container_width=True):
                            result = manager.update_crawler(crawler['name'], enabled=False)
                            if result['success']:
                                st.success(result['message'])
                                st.rerun()
                    else:
                        if st.button("âœ… å¯ç”¨", key=f"enable_{crawler['name']}", use_container_width=True):
                            result = manager.update_crawler(crawler['name'], enabled=True)
                            if result['success']:
                                st.success(result['message'])
                                st.rerun()
                    
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{crawler['name']}", use_container_width=True):
                        result = manager.delete_crawler(crawler['name'])
                        if result['success']:
                            st.success(result['message'])
                            st.rerun()
                        else:
                            st.error(result['message'])
                
                # æ˜¾ç¤ºä»£ç ï¼ˆå¦‚æœç”¨æˆ·ç‚¹å‡»äº†æŸ¥çœ‹æŒ‰é’®ï¼‰
                if st.session_state.get(f'viewing_code_{crawler["name"]}', False):
                    code = manager.get_crawler_code(crawler['name'])
                    if code:
                        st.code(code, language='python')
                        if st.button("å…³é—­ä»£ç ", key=f"close_code_{crawler['name']}"):
                            st.session_state[f'viewing_code_{crawler["name"]}'] = False
                            st.rerun()


def render_add_crawler(manager: CrawlerManager):
    """æ¸²æŸ“æ·»åŠ çˆ¬è™«ç•Œé¢"""
    st.markdown("### â• æ·»åŠ æ–°çˆ¬è™«")
    st.info("ğŸ’¡ æç¤º: ç²˜è´´æ‚¨çš„çˆ¬è™«ä»£ç ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨éªŒè¯å¹¶ä¿å­˜ã€‚ä»£ç ä¸­éœ€è¦åŒ…å« `scrape()`, `run()` æˆ– `main()` å‡½æ•°ã€‚")
    
    with st.form("add_crawler_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            name = st.text_input(
                "çˆ¬è™«åç§° *", 
                placeholder="ä¾‹å¦‚: my_amazon_crawler",
                help="ä½¿ç”¨è‹±æ–‡å’Œä¸‹åˆ’çº¿ï¼Œä¸è¦åŒ…å«ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦"
            )
        
        with col2:
            platform = st.selectbox(
                "å¹³å°ç±»å‹",
                ["custom", "amazon", "ebay", "shopee", "aliexpress", 
                 "tiktok", "youtube", "other"]
            )
        
        description = st.text_area(
            "çˆ¬è™«æè¿°",
            placeholder="ç®€è¦æè¿°è¿™ä¸ªçˆ¬è™«çš„åŠŸèƒ½...",
            height=80
        )
        
        st.markdown("#### çˆ¬è™«ä»£ç ")
        st.caption("è¯·ç²˜è´´å®Œæ•´çš„Pythonä»£ç ã€‚ç¡®ä¿ä»£ç ä¸­åŒ…å« `scrape()`, `run()` æˆ– `main()` å‡½æ•°ä½œä¸ºå…¥å£ç‚¹ã€‚")
        
        code = st.text_area(
            "Pythonä»£ç  *",
            placeholder="""# ç¤ºä¾‹çˆ¬è™«ä»£ç 
import requests
from bs4 import BeautifulSoup

def scrape(url, **kwargs):
    '''ä¸»è¦çˆ¬å–å‡½æ•°'''
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # ä½ çš„çˆ¬å–é€»è¾‘
    data = []
    
    return {
        'success': True,
        'data': data,
        'count': len(data)
    }
""",
            height=400,
            help="ä»£ç å¿…é¡»æ˜¯æœ‰æ•ˆçš„Pythonä»£ç "
        )
        
        # æä¾›ç¤ºä¾‹ä»£ç 
        with st.expander("ğŸ“– æŸ¥çœ‹ç¤ºä¾‹ä»£ç æ¨¡æ¿"):
            st.code("""# åŸºç¡€çˆ¬è™«æ¨¡æ¿
import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

def scrape(url, max_items=10, **kwargs):
    '''
    ä¸»è¦çˆ¬å–å‡½æ•°
    
    å‚æ•°:
        url: è¦çˆ¬å–çš„URL
        max_items: æœ€å¤§é¡¹ç›®æ•°
        **kwargs: å…¶ä»–å‚æ•°
        
    è¿”å›:
        åŒ…å«çˆ¬å–ç»“æœçš„å­—å…¸
    '''
    try:
        # å‘é€è¯·æ±‚
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # è§£æHTML
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # æå–æ•°æ® (æ ¹æ®å®é™…ç½‘ç«™ç»“æ„ä¿®æ”¹)
        items = []
        for item in soup.select('.item-selector')[:max_items]:
            title = item.select_one('.title')
            price = item.select_one('.price')
            
            items.append({
                'title': title.text.strip() if title else '',
                'price': price.text.strip() if price else '',
                'scraped_at': datetime.now().isoformat()
            })
        
        return {
            'success': True,
            'data': items,
            'count': len(items),
            'url': url
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'data': []
        }
""", language='python')
        
        submitted = st.form_submit_button("ğŸ’¾ ä¿å­˜çˆ¬è™«", use_container_width=True)
        
        if submitted:
            if not name or not code:
                st.error("âŒ è¯·å¡«å†™çˆ¬è™«åç§°å’Œä»£ç ")
            elif ' ' in name or not name.replace('_', '').isalnum():
                st.error("âŒ çˆ¬è™«åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿")
            else:
                # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
                if manager.get_crawler(name):
                    st.error(f"âŒ çˆ¬è™«åç§° '{name}' å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–åç§°")
                else:
                    result = manager.add_crawler(
                        name=name,
                        code=code,
                        description=description,
                        platform=platform
                    )
                    
                    if result['success']:
                        st.success(f"âœ… {result['message']}")
                        st.balloons()
                        # æ¸…ç©ºè¡¨å•ï¼ˆé€šè¿‡é‡æ–°åŠ è½½ï¼‰
                        st.rerun()
                    else:
                        st.error(f"âŒ {result['message']}")
                        if 'error' in result:
                            st.code(result['error'])


def render_edit_crawler(manager: CrawlerManager):
    """æ¸²æŸ“ç¼–è¾‘çˆ¬è™«ç•Œé¢"""
    st.markdown("### ğŸ”§ ç¼–è¾‘çˆ¬è™«")
    
    crawlers = manager.list_crawlers()
    
    if not crawlers:
        st.info("æš‚æ— çˆ¬è™«å¯ç¼–è¾‘ï¼Œè¯·å…ˆæ·»åŠ çˆ¬è™«")
        return
    
    # é€‰æ‹©è¦ç¼–è¾‘çš„çˆ¬è™«
    crawler_names = [c['name'] for c in crawlers]
    selected_name = st.selectbox("é€‰æ‹©è¦ç¼–è¾‘çš„çˆ¬è™«", crawler_names)
    
    if selected_name:
        crawler = manager.get_crawler(selected_name)
        current_code = manager.get_crawler_code(selected_name)
        
        if crawler and current_code:
            with st.form("edit_crawler_form"):
                st.markdown(f"#### ç¼–è¾‘çˆ¬è™«: {selected_name}")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    platform = st.selectbox(
                        "å¹³å°ç±»å‹",
                        ["custom", "amazon", "ebay", "shopee", "aliexpress", 
                         "tiktok", "youtube", "other"],
                        index=["custom", "amazon", "ebay", "shopee", "aliexpress", 
                               "tiktok", "youtube", "other"].index(crawler.get('platform', 'custom'))
                    )
                
                with col2:
                    enabled = st.checkbox("å¯ç”¨çˆ¬è™«", value=crawler.get('enabled', True))
                
                description = st.text_area(
                    "çˆ¬è™«æè¿°",
                    value=crawler.get('description', ''),
                    height=80
                )
                
                st.markdown("#### çˆ¬è™«ä»£ç ")
                code = st.text_area(
                    "Pythonä»£ç ",
                    value=current_code,
                    height=400
                )
                
                col1, col2 = st.columns(2)
                
                with col1:
                    submitted = st.form_submit_button("ğŸ’¾ ä¿å­˜æ›´æ–°", use_container_width=True)
                
                with col2:
                    if st.form_submit_button("ğŸ”„ é‡ç½®", use_container_width=True):
                        st.rerun()
                
                if submitted:
                    result = manager.update_crawler(
                        name=selected_name,
                        code=code,
                        description=description,
                        enabled=enabled
                    )
                    
                    if result['success']:
                        st.success(f"âœ… {result['message']}")
                        st.rerun()
                    else:
                        st.error(f"âŒ {result['message']}")
                        if 'error' in result:
                            st.code(result['error'])


def render_execute_crawler(manager: CrawlerManager):
    """æ¸²æŸ“æ‰§è¡Œçˆ¬è™«ç•Œé¢"""
    st.markdown("### â–¶ï¸ æ‰§è¡Œçˆ¬è™«")
    st.info("é€‰æ‹©ä¸€ä¸ªçˆ¬è™«å¹¶é…ç½®å‚æ•°æ¥è¿è¡Œ")
    
    crawlers = manager.list_crawlers(enabled_only=True)
    
    if not crawlers:
        st.warning("æš‚æ— å·²å¯ç”¨çš„çˆ¬è™«ï¼Œè¯·å…ˆæ·»åŠ å¹¶å¯ç”¨çˆ¬è™«")
        return
    
    # é€‰æ‹©çˆ¬è™«
    crawler_names = [c['name'] for c in crawlers]
    selected_name = st.selectbox("é€‰æ‹©è¦æ‰§è¡Œçš„çˆ¬è™«", crawler_names)
    
    if selected_name:
        crawler = manager.get_crawler(selected_name)
        
        st.markdown(f"#### æ‰§è¡Œçˆ¬è™«: {selected_name}")
        st.caption(f"å¹³å°: {crawler.get('platform', 'custom')} | æè¿°: {crawler.get('description', 'æ— ')}")
        
        with st.form("execute_crawler_form"):
            st.markdown("##### é…ç½®å‚æ•°")
            
            url = st.text_input(
                "ç›®æ ‡URL",
                placeholder="https://example.com",
                help="è¦çˆ¬å–çš„ç½‘é¡µåœ°å€"
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                max_items = st.number_input("æœ€å¤§é¡¹ç›®æ•°", min_value=1, max_value=1000, value=10)
            
            with col2:
                timeout = st.number_input("è¶…æ—¶æ—¶é—´(ç§’)", min_value=5, max_value=300, value=30)
            
            # é¢å¤–å‚æ•°
            with st.expander("é«˜çº§å‚æ•° (JSONæ ¼å¼)"):
                extra_params = st.text_area(
                    "é¢å¤–å‚æ•°",
                    value='{}',
                    help="ä»¥JSONæ ¼å¼æä¾›é¢å¤–å‚æ•°ï¼Œä¾‹å¦‚: {\"headers\": {\"Authorization\": \"Bearer token\"}}"
                )
            
            submitted = st.form_submit_button("ğŸš€ å¼€å§‹æ‰§è¡Œ", use_container_width=True)
            
            if submitted:
                if not url:
                    st.error("âŒ è¯·è¾“å…¥ç›®æ ‡URL")
                else:
                    # è§£æé¢å¤–å‚æ•°
                    try:
                        extra = json.loads(extra_params)
                    except:
                        extra = {}
                    
                    # æ‰§è¡Œçˆ¬è™«
                    with st.spinner(f"æ­£åœ¨æ‰§è¡Œçˆ¬è™« {selected_name}..."):
                        result = manager.execute_crawler(
                            selected_name,
                            url=url,
                            max_items=max_items,
                            timeout=timeout,
                            **extra
                        )
                    
                    if result['success']:
                        st.success(f"âœ… {result['message']}")
                        
                        # æ˜¾ç¤ºç»“æœ
                        if 'result' in result:
                            st.markdown("#### æ‰§è¡Œç»“æœ")
                            
                            # å°è¯•ä»¥å‹å¥½çš„æ–¹å¼æ˜¾ç¤ºç»“æœ
                            crawler_result = result['result']
                            
                            if isinstance(crawler_result, dict):
                                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    if 'count' in crawler_result:
                                        st.metric("è·å–é¡¹ç›®æ•°", crawler_result['count'])
                                
                                with col2:
                                    if 'success' in crawler_result:
                                        status = "âœ… æˆåŠŸ" if crawler_result['success'] else "âŒ å¤±è´¥"
                                        st.metric("çŠ¶æ€", status)
                                
                                with col3:
                                    if 'data' in crawler_result and isinstance(crawler_result['data'], list):
                                        st.metric("æ•°æ®è¡Œæ•°", len(crawler_result['data']))
                                
                                # æ˜¾ç¤ºè¯¦ç»†æ•°æ®
                                with st.expander("æŸ¥çœ‹è¯¦ç»†æ•°æ®", expanded=True):
                                    st.json(crawler_result)
                                
                                # æä¾›ä¸‹è½½é€‰é¡¹
                                if 'data' in crawler_result:
                                    json_str = json.dumps(crawler_result['data'], 
                                                        ensure_ascii=False, indent=2)
                                    st.download_button(
                                        label="ğŸ“¥ ä¸‹è½½ç»“æœ(JSON)",
                                        data=json_str,
                                        file_name=f"{selected_name}_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                                        mime="application/json"
                                    )
                            else:
                                # ç›´æ¥æ˜¾ç¤ºç»“æœ
                                st.json(crawler_result)
                    else:
                        st.error(f"âŒ {result['message']}")
                        if 'error' in result:
                            st.code(result['error'])
