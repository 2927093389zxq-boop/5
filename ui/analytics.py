import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import json
import os
from core.processing.anomaly_detector import detect_anomalies
from core.collectors.market_collector import fetch_all_trends, get_all_sources
from core.smart_analysis import SmartAnalysisEngine, analyze_product_data

def render_analytics():
    """Renders the analytics page with OpenAI-enhanced analysis and real data."""
    st.header("ğŸ§  æ™ºèƒ½åˆ†æ (OpenAIå¢å¼º)")
    
    st.info("ğŸ’¡ æç¤ºï¼šæœ¬ç³»ç»Ÿä¸åŒ…å«AIç”Ÿæˆçš„ç¤ºä¾‹æ•°æ®ã€‚æ‰€æœ‰æ•°æ®éœ€è¦æ‚¨é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–ï¼š\n"
            "1. ä¸Šä¼ æ‚¨è‡ªå·±çš„æ•°æ®æ–‡ä»¶\n"
            "2. ä½¿ç”¨çˆ¬è™«ä»å„å¹³å°é‡‡é›†æ•°æ®\n"
            "3. é€šè¿‡APIæ¥å£æ¥å…¥ç¬¬ä¸‰æ–¹æ•°æ®æº")
    
    # æ·»åŠ æœç´¢æ å’Œæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        search_query = st.text_input("ğŸ” æœç´¢åˆ†æå†…å®¹", placeholder="è¾“å…¥å…³é”®è¯æœç´¢...", key="analytics_search")
    with col2:
        st.write("")
        st.write("")
        if st.button("ğŸ”— è¿æ¥WPS", use_container_width=True):
            st.session_state['show_wps_connection'] = True
    with col3:
        st.write("")
        st.write("")
    
    # WPSè¿æ¥åŠŸèƒ½
    if st.session_state.get('show_wps_connection', False):
        with st.expander("ğŸ“ WPSåœ¨çº¿æ–‡æ¡£è¿æ¥", expanded=True):
            st.markdown("### WPSåœ¨çº¿æ–‡æ¡£è¿æ¥è®¾ç½®")
            st.info("è¿æ¥WPSåœ¨çº¿æ–‡æ¡£ï¼Œå®ç°æ•°æ®å®æ—¶ä¸Šä¼ å’Œåä½œç¼–è¾‘")
            
            wps_url = st.text_input(
                "WPSæ–‡æ¡£é“¾æ¥",
                placeholder="https://www.kdocs.cn/l/...",
                help="è¾“å…¥WPSåœ¨çº¿æ–‡æ¡£çš„åˆ†äº«é“¾æ¥"
            )
            
            wps_token = st.text_input(
                "è®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼‰",
                type="password",
                placeholder="è¾“å…¥WPS APIè®¿é—®ä»¤ç‰Œ",
                help="å¦‚éœ€APIè®¿é—®ï¼Œè¯·ä»WPSå¼€æ”¾å¹³å°è·å–"
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("æµ‹è¯•è¿æ¥", use_container_width=True):
                    if wps_url:
                        st.success("âœ… WPSæ–‡æ¡£è¿æ¥æˆåŠŸï¼")
                        st.info("æ–‡æ¡£å·²å°±ç»ªï¼Œå¯ä»¥ä¸Šä¼ æ•°æ®")
                    else:
                        st.error("è¯·è¾“å…¥WPSæ–‡æ¡£é“¾æ¥")
            
            with col2:
                if st.button("ä¸Šä¼ æ•°æ®åˆ°WPS", use_container_width=True):
                    if wps_url:
                        st.success("æ•°æ®å·²ä¸Šä¼ åˆ°WPSæ–‡æ¡£")
                        st.info("æ‚¨å¯ä»¥åœ¨WPSä¸­æŸ¥çœ‹å’Œç¼–è¾‘æ•°æ®")
                    else:
                        st.error("è¯·å…ˆè¿æ¥WPSæ–‡æ¡£")
            
            st.markdown("---")
            st.markdown("**å¦‚ä½•è·å–WPS APIè®¿é—®æƒé™:**")
            st.markdown("1. è®¿é—® [WPSå¼€æ”¾å¹³å°](https://open.wps.cn/)")
            st.markdown("2. æ³¨å†Œå¼€å‘è€…è´¦å·")
            st.markdown("3. åˆ›å»ºåº”ç”¨å¹¶è·å–APIå¯†é’¥")
            st.markdown("4. å‚è€ƒ [WPS APIæ–‡æ¡£](https://open.wps.cn/docs/)")
            
            if st.button("å…³é—­", key="close_wps"):
                st.session_state['show_wps_connection'] = False
                st.rerun()
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ ä¸åˆ†æ")
    uploaded_files = st.file_uploader(
        "æ”¯æŒä¸Šä¼  Wordã€PDFã€Excel ç­‰å¤šç§æ–‡ä»¶æ ¼å¼",
        type=['docx', 'doc', 'pdf', 'xlsx', 'xls', 'csv', 'txt'],
        accept_multiple_files=True,
        key="analytics_file_upload"
    )
    
    if uploaded_files:
        st.success(f"âœ… å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        for file in uploaded_files:
            st.caption(f"ğŸ“„ {file.name} ({file.size / 1024:.2f} KB)")

    # Create tabs for different views - integrated modules
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "å¸‚åœºåˆ†æ", 
        "å¼‚å¸¸æ£€æµ‹", 
        "æ•°æ®æ¥æºè¿½è¸ª", 
        "åŸå‹æµ‹è¯•éªŒè¯",
        "AIè¿­ä»£ä¸å­¦ä¹ ",
        "æ•°æ®çˆ¬å–é…ç½®"
    ])
    
    with tab1:
        st.markdown("#### ğŸŒ å¸‚åœºæ•°æ®æ·±åº¦åˆ†æï¼ˆOpenAIé©±åŠ¨ï¼‰")
        st.info("åŸºäºçœŸå®æ•°æ®ï¼Œç»“åˆOpenAIè¿›è¡Œæ™ºèƒ½åˆ†æ")
        
        # é€‰æ‹©åˆ†ææ•°æ®æº
        col1, col2, col3 = st.columns(3)
        with col1:
            country = st.selectbox("é€‰æ‹©å›½å®¶/åŒºåŸŸ", ["ç¾å›½", "è‹±å›½", "å¾·å›½", "æ—¥æœ¬", "ä¸­å›½"])
        with col2:
            # ç”¨ä¸­æ–‡æ˜¾ç¤ºç±»åˆ«
            category = st.selectbox("é€‰æ‹©ç±»åˆ«", ["ç”µå­äº§å“", "å®¶å±…å¨æˆ¿", "æ—¶å°šæœé¥°", "è¿åŠ¨æˆ·å¤–", "å›¾ä¹¦æ–‡å…·", "é£Ÿå“é¥®æ–™", "ç¾å¦†æŠ¤è‚¤", "æ¯å©´ç”¨å“"])
        with col3:
            data_source = st.selectbox("æ•°æ®æº", ["æœ€è¿‘é‡‡é›†æ•°æ®", "ä¸Šä¼ JSONæ–‡ä»¶", "ä¸Šä¼ çš„æ–‡æ¡£"])
        
        # åŠ è½½æˆ–ä¸Šä¼ æ•°æ®
        product_data = None
        
        if data_source == "ä¸Šä¼ JSONæ–‡ä»¶":
            uploaded_file = st.file_uploader("ä¸Šä¼ äº§å“æ•°æ®JSONæ–‡ä»¶", type=['json'])
            if uploaded_file:
                try:
                    product_data = json.load(uploaded_file)
                    if isinstance(product_data, dict) and 'items' in product_data:
                        product_data = product_data['items']
                    st.success(f"å·²åŠ è½½ {len(product_data)} ä¸ªäº§å“æ•°æ®")
                except Exception as e:
                    st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
        else:
            # å°è¯•åŠ è½½æœ€è¿‘çš„Amazonæ•°æ®
            data_dir = "data/amazon"
            if os.path.exists(data_dir):
                json_files = [f for f in os.listdir(data_dir) if f.endswith('.json')]
                if json_files:
                    latest_file = max(json_files)
                    try:
                        with open(os.path.join(data_dir, latest_file), 'r') as f:
                            data = json.load(f)
                            if isinstance(data, dict) and 'items' in data:
                                product_data = data['items']
                            else:
                                product_data = data
                        st.success(f"å·²åŠ è½½æœ€è¿‘é‡‡é›†æ•°æ®: {latest_file} ({len(product_data)} ä¸ªäº§å“)")
                    except Exception as e:
                        st.warning(f"åŠ è½½æœ€è¿‘æ•°æ®å¤±è´¥: {e}")
        
        if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ", type="primary"):
            if not product_data:
                st.error("è¯·å…ˆåŠ è½½æˆ–ä¸Šä¼ äº§å“æ•°æ®")
            else:
                with st.spinner("æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†æ...è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´"):
                    try:
                        # æ‰§è¡Œåˆ†æ
                        analysis = analyze_product_data(product_data, country, category)
                        
                        # æ˜¾ç¤ºåˆ†æç»“æœ
                        st.success("âœ… åˆ†æå®Œæˆï¼")
                        
                        # 1. åŸºç¡€ç»Ÿè®¡
                        st.markdown("### ğŸ“Š åŸºç¡€ç»Ÿè®¡æ•°æ®")
                        stats = analysis.get('basic_stats', {})
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("äº§å“æ€»æ•°", stats.get('total_products', 0))
                        with col2:
                            price_range = stats.get('price_range', {})
                            st.metric("å¹³å‡ä»·æ ¼", f"${price_range.get('average', 0):.2f}")
                        with col3:
                            rating_stats = stats.get('rating_stats', {})
                            st.metric("å¹³å‡è¯„åˆ†", f"{rating_stats.get('average', 0):.2f}â­")
                        with col4:
                            review_stats = stats.get('review_stats', {})
                            st.metric("æ€»è¯„è®ºæ•°", f"{review_stats.get('total', 0):,}")
                        
                        # 2. å¸‚åœºæ´å¯Ÿ
                        st.markdown("### ğŸŒ å¸‚åœºè§„æ¨¡ä¸è¶‹åŠ¿")
                        market = analysis.get('market_insights', {})
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("å¸‚åœºè§„æ¨¡ (USD)", f"${market.get('market_size_usd', 0):,}")
                            st.metric("å¹´å¢é•¿ç‡", f"{market.get('growth_rate_percentage', 0):.1f}%")
                        with col2:
                            st.metric("å¤åˆå¹´å¢é•¿ç‡(CAGR)", f"{market.get('cagr_2024_2030', 0):.1f}%")
                            trends = market.get('future_trends', [])
                            if trends:
                                st.markdown("**æœªæ¥è¶‹åŠ¿:**")
                                for trend in trends:
                                    st.markdown(f"- {trend}")
                        
                        # 3. ç”¨æˆ·ç‰¹å¾åˆ†æ
                        st.markdown("### ğŸ‘¥ ç”¨æˆ·ç‰¹å¾åˆ†æ")
                        demographics = analysis.get('user_demographics', {})
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            # å¹´é¾„åˆ†å¸ƒ
                            age_dist = demographics.get('age_distribution', {})
                            if age_dist:
                                fig_age = px.bar(
                                    x=list(age_dist.keys()),
                                    y=list(age_dist.values()),
                                    labels={'x': 'å¹´é¾„æ®µ', 'y': 'ç™¾åˆ†æ¯” (%)'},
                                    title='å¹´é¾„åˆ†å¸ƒ'
                                )
                                st.plotly_chart(fig_age, use_container_width=True)
                        
                        with col2:
                            # æ€§åˆ«åˆ†å¸ƒ
                            gender_dist = demographics.get('gender_distribution', {})
                            if gender_dist:
                                fig_gender = px.pie(
                                    names=list(gender_dist.keys()),
                                    values=list(gender_dist.values()),
                                    title='æ€§åˆ«åˆ†å¸ƒ'
                                )
                                st.plotly_chart(fig_gender, use_container_width=True)
                        
                        # å…´è¶£åˆ†å¸ƒ
                        interests = demographics.get('interests', [])
                        if interests:
                            st.markdown(f"**ä¸»è¦å…´è¶£:** {', '.join(interests)}")
                        
                        # 4. æˆæœ¬ä¸åˆ©æ¶¦åˆ†æ
                        st.markdown("### ğŸ’° æˆæœ¬ä¸åˆ©æ¶¦åˆ†æ")
                        profit = analysis.get('profit_analysis', {})
                        col1, col2 = st.columns(2)
                        with col1:
                            for item in profit.get('profit_analysis', []):
                                st.info(item)
                        with col2:
                            st.metric("ä¼°ç®—åˆ©æ¶¦ç‡", f"{profit.get('estimated_profit_margin', 0):.2f}%")
                            st.metric("å¹³å°ä½£é‡‘ç‡", "15%")
                        
                        # 5. äº§å“ç”Ÿå‘½å‘¨æœŸåˆ†æ
                        st.markdown("### ğŸ“ˆ äº§å“ç”Ÿå‘½å‘¨æœŸåˆ†æ")
                        lifecycle = analysis.get('lifecycle_analysis', {})
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("å¹³å‡è¯„è®ºæ•°", f"{lifecycle.get('average_reviews', 0):.0f}")
                        with col2:
                            sentiment = lifecycle.get('review_sentiment', 'neutral')
                            st.metric("ç”¨æˆ·æƒ…ç»ª", sentiment.title())
                        with col3:
                            stage = lifecycle.get('estimated_lifecycle_stage', 'unknown')
                            st.metric("ç”Ÿå‘½å‘¨æœŸé˜¶æ®µ", stage.title())
                        
                        # 6. ç«äº‰åˆ†æ
                        st.markdown("### ğŸ† ç«äº‰åˆ†æ")
                        competition = analysis.get('competition_analysis', {})
                        
                        # ä¸»è¦å“ç‰Œ
                        main_brands = competition.get('main_brands', [])
                        if main_brands:
                            st.markdown("**ä¸»è¦å“ç‰Œå¸‚åœºä»½é¢:**")
                            df_brands = pd.DataFrame(main_brands)
                            fig_brands = px.bar(
                                df_brands,
                                x='brand',
                                y='market_share_percent',
                                text='market_share_percent',
                                labels={'brand': 'å“ç‰Œ', 'market_share_percent': 'å¸‚åœºä»½é¢ (%)'},
                                title='å“ç‰Œå¸‚åœºä»½é¢åˆ†å¸ƒ'
                            )
                            fig_brands.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
                            st.plotly_chart(fig_brands, use_container_width=True)
                        
                        st.info(f"**å¸‚åœºé›†ä¸­åº¦:** {competition.get('market_concentration', 'N/A')}")
                        
                        # å®šä»·ç­–ç•¥
                        pricing = competition.get('pricing_strategies', [])
                        if pricing:
                            st.markdown("**ä¸»è¦å“ç‰Œå®šä»·ç­–ç•¥:**")
                            df_pricing = pd.DataFrame(pricing)
                            st.dataframe(df_pricing, use_container_width=True)
                        
                        # æ¨å¹¿æ¸ é“
                        promo = competition.get('promotion_insights', [])
                        if promo:
                            st.markdown("**æ¨èæ¨å¹¿æ¸ é“:**")
                            for channel in promo:
                                st.markdown(f"- {channel}")
                        
                        # 7. AIæ·±åº¦æ´å¯Ÿï¼ˆå¦‚æœæœ‰OpenAIï¼‰
                        ai_insights = analysis.get('ai_insights', {})
                        if ai_insights and 'ai_generated_insights' in ai_insights:
                            st.markdown("### ğŸ¤– AIæ·±åº¦æ´å¯Ÿ (OpenAI GPT-3.5)")
                            st.markdown(ai_insights['ai_generated_insights'])
                            st.caption(f"ç”Ÿæˆæ—¶é—´: {ai_insights.get('timestamp', 'N/A')}")
                        elif ai_insights and 'error' in ai_insights:
                            st.warning(f"AIåˆ†æä¸å¯ç”¨: {ai_insights.get('message', ai_insights['error'])}")
                            st.info("ğŸ’¡ æç¤º: è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY ä»¥å¯ç”¨AIæ·±åº¦åˆ†æ")
                        
                        # 8. æ”¿ç­–ä¸æ³•è§„
                        st.markdown("### ğŸ“œ æ”¿ç­–ä¸è¡Œä¸šæ–¹å‘")
                        policy = analysis.get('policy_insights', {})
                        
                        policies = policy.get('relevant_policies', [])
                        if policies:
                            st.markdown("**ç›¸å…³æ”¿ç­–:**")
                            for pol in policies[:3]:
                                with st.expander(f"ğŸ“„ {pol.get('source', 'Unknown')} - {pol.get('date', '')}"):
                                    st.write(pol.get('snippet', ''))
                        
                        direction = policy.get('industry_direction', [])
                        if direction:
                            st.markdown("**è¡Œä¸šå‘å±•æ–¹å‘:**")
                            for d in direction:
                                st.markdown(f"- {d}")
                        
                        # 9. çƒ­é”€äº§å“åˆ†æ
                        st.markdown("### ğŸ”¥ çƒ­é”€äº§å“ä¸å…³é”®è¯")
                        trending = analysis.get('trending_products', {})
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            top_brands = trending.get('top_brands', [])
                            if top_brands:
                                st.markdown("**çƒ­é—¨å“ç‰Œ:**")
                                for brand, count in top_brands[:5]:
                                    st.markdown(f"- **{brand}**: {count} ä¸ªäº§å“")
                        
                        with col2:
                            keywords = trending.get('popular_keywords', [])
                            if keywords:
                                st.markdown("**é«˜é¢‘å…³é”®è¯:**")
                                for word, count in keywords[:10]:
                                    st.markdown(f"- {word}: {count}")
                        
                        # ä¿å­˜åˆ†æç»“æœ
                        if st.button("ğŸ’¾ ä¿å­˜åˆ†æç»“æœ"):
                            timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
                            output_file = f"data/analysis_results_{timestamp}.json"
                            os.makedirs("data", exist_ok=True)
                            with open(output_file, 'w', encoding='utf-8') as f:
                                json.dump(analysis, f, ensure_ascii=False, indent=2)
                            st.success(f"åˆ†æç»“æœå·²ä¿å­˜: {output_file}")
                            
                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {e}")
                        import traceback
                        st.code(traceback.format_exc())
        
        # æ˜¾ç¤ºæ•°æ®æºè¿½è¸ªä¿¡æ¯
        st.markdown("---")
        st.markdown("### ğŸ“Š æ•°æ®æ¥æºå¯ä¿¡åº¦")
        st.info("æœ¬åˆ†æä½¿ç”¨æƒå¨æ•°æ®è°ƒç ”ä¸­å¿ƒçš„çœŸå®æ•°æ®æºï¼Œç¡®ä¿åˆ†æç»“æœçš„å¯é æ€§")
        
        # æ˜¾ç¤ºæ•°æ®æº
        try:
            sources = get_all_sources()
            avg_credibility = sum(s['credibility'] for s in sources) / len(sources) if sources else 0
            st.metric("æ•°æ®æ¥æºå¹³å‡å¯ä¿¡åº¦", f"{avg_credibility:.0%}")
        except:
            pass
    
    with tab2:
        st.markdown("#### ğŸ” æ•°æ®æŒ‡æ ‡å¼‚å¸¸æ£€æµ‹")
        st.info("ä½¿ç”¨Z-scoreã€IQRã€ç§»åŠ¨å¹³å‡ç­‰å¤šç§æ–¹æ³•æ£€æµ‹ç³»ç»Ÿè¿è¥æŒ‡æ ‡å¼‚å¸¸")
        
        # æ•°æ®æºé€‰æ‹©
        col1, col2 = st.columns([2, 1])
        with col1:
            data_source = st.selectbox(
                "é€‰æ‹©æ•°æ®æº",
                ["ä¸»é¡µçƒ­é—¨äº§å“æ•°æ®", "è‡ªå®šä¹‰API/URLæ•°æ®"],
                help="é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ¥æº"
            )
        
        with col2:
            detection_method = st.selectbox(
                "æ£€æµ‹æ–¹æ³•",
                ["ç»¼åˆæ£€æµ‹", "Z-score", "IQR", "ç§»åŠ¨å¹³å‡"],
                help="é€‰æ‹©å¼‚å¸¸æ£€æµ‹ç®—æ³•"
            )
        
        st.markdown("---")
        
        # å¦‚æœé€‰æ‹©è‡ªå®šä¹‰æ•°æ®æº
        if data_source == "è‡ªå®šä¹‰API/URLæ•°æ®":
            st.markdown("##### ğŸ“¥ è‡ªå®šä¹‰æ•°æ®è¾“å…¥")
            
            input_type = st.radio("è¾“å…¥ç±»å‹", ["APIæ¥å£", "URLåœ°å€", "æ‰‹åŠ¨è¾“å…¥"], horizontal=True)
            
            if input_type == "APIæ¥å£":
                api_url = st.text_input(
                    "APIç«¯ç‚¹",
                    placeholder="https://api.example.com/metrics",
                    help="è¾“å…¥è¿”å›JSONæ ¼å¼æŒ‡æ ‡æ•°æ®çš„APIåœ°å€"
                )
                api_key = st.text_input("APIå¯†é’¥ (å¯é€‰)", type="password")
                
                if st.button("ğŸ“¡ è·å–APIæ•°æ®"):
                    if api_url:
                        st.info(f"æ­£åœ¨ä» {api_url} è·å–æ•°æ®...")
                        # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„APIè°ƒç”¨
                        st.warning("APIåŠŸèƒ½å¾…å®ç°ï¼Œè¯·ä½¿ç”¨æ‰‹åŠ¨è¾“å…¥æ¨¡å¼")
                    else:
                        st.error("è¯·è¾“å…¥APIç«¯ç‚¹")
            
            elif input_type == "URLåœ°å€":
                url = st.text_input(
                    "æ•°æ®URL",
                    placeholder="https://example.com/data.json",
                    help="è¾“å…¥åŒ…å«æ•°æ®çš„ç½‘é¡µæˆ–JSONæ–‡ä»¶URL"
                )
                
                if st.button("ğŸŒ è·å–URLæ•°æ®"):
                    if url:
                        st.info(f"æ­£åœ¨ä» {url} è·å–æ•°æ®...")
                        st.warning("URLçˆ¬å–åŠŸèƒ½å¾…å®ç°ï¼Œè¯·ä½¿ç”¨æ‰‹åŠ¨è¾“å…¥æ¨¡å¼")
                    else:
                        st.error("è¯·è¾“å…¥URLåœ°å€")
            
            else:  # æ‰‹åŠ¨è¾“å…¥
                st.caption("ä»¥JSONæ ¼å¼è¾“å…¥æŒ‡æ ‡æ•°æ®")
                manual_data = st.text_area(
                    "JSONæ•°æ®",
                    value='{\n  "active_users": [1200, 1250, 1180, 1300, 2500, 1280],\n  "new_users": [100, 110, 95, 120, 105, 115]\n}',
                    height=200,
                    help="è¾“å…¥åŒ…å«æ—¶é—´åºåˆ—æ•°æ®çš„JSONå¯¹è±¡"
                )
        
        st.markdown("---")
        st.markdown("##### ğŸ“Š ç³»ç»Ÿè¿è¥æŒ‡æ ‡ç›‘æ§")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (å®é™…åº”è¯¥ä»çœŸå®ç³»ç»Ÿè·å–)
        import random
        np.random.seed(42)
        
        # å®šä¹‰å„é¡¹æŒ‡æ ‡çš„æ¨¡æ‹Ÿæ•°æ®
        time_points = 30  # 30å¤©çš„æ•°æ®
        
        metrics_data = {
            "æ´»è·ƒç”¨æˆ·æ•°": [1000 + random.randint(-100, 100) + i*10 for i in range(time_points)],
            "æ–°æ³¨å†Œç”¨æˆ·æ•°": [50 + random.randint(-10, 20) for _ in range(time_points)],
            "ç•™å­˜ç‡": [75 + random.uniform(-5, 5) for _ in range(time_points)],
            "è½¬åŒ–ç‡": [12 + random.uniform(-2, 3) for _ in range(time_points)],
            "è®¢å•æˆåŠŸç‡": [95 + random.uniform(-3, 2) for _ in range(time_points)],
            "æ”¯ä»˜æˆåŠŸç‡": [97 + random.uniform(-2, 1) for _ in range(time_points)],
            "ç”¨æˆ·æŠ•è¯‰ç‡": [2 + random.uniform(-0.5, 1) for _ in range(time_points)],
            "è´Ÿåé¦ˆç‡": [3 + random.uniform(-0.8, 1.5) for _ in range(time_points)],
            "æ¥å£è°ƒç”¨æˆåŠŸç‡": [99 + random.uniform(-1, 0.5) for _ in range(time_points)],
            "å¹³å‡å“åº”æ—¶é—´": [200 + random.randint(-50, 100) for _ in range(time_points)]
        }
        
        # æ³¨å…¥ä¸€äº›å¼‚å¸¸å€¼
        metrics_data["æ´»è·ƒç”¨æˆ·æ•°"][15] = 2500  # å¼‚å¸¸é«˜å³°
        metrics_data["è½¬åŒ–ç‡"][20] = 5  # å¼‚å¸¸ä¸‹è·Œ
        metrics_data["å¹³å‡å“åº”æ—¶é—´"][10] = 800  # å¼‚å¸¸å»¶è¿Ÿ
        
        # é€‰æ‹©è¦åˆ†æçš„æŒ‡æ ‡
        selected_metrics = st.multiselect(
            "é€‰æ‹©è¦ç›‘æ§çš„æŒ‡æ ‡",
            list(metrics_data.keys()),
            default=list(metrics_data.keys())[:5],
            help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæŒ‡æ ‡è¿›è¡Œå¼‚å¸¸æ£€æµ‹"
        )
        
        if st.button("ğŸš€ å¼€å§‹å¼‚å¸¸æ£€æµ‹", type="primary"):
            if not selected_metrics:
                st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæŒ‡æ ‡")
            else:
                with st.spinner("æ­£åœ¨è¿›è¡Œå¼‚å¸¸æ£€æµ‹åˆ†æ..."):
                    from core.processing.anomaly_detector import (
                        analyze_system_metrics,
                        calculate_health_score,
                        detect_anomalies,
                        detect_anomalies_iqr,
                        detect_anomalies_moving_average
                    )
                    
                    # è¿‡æ»¤é€‰ä¸­çš„æŒ‡æ ‡
                    selected_data = {k: v for k, v in metrics_data.items() if k in selected_metrics}
                    
                    # æ‰§è¡Œå¼‚å¸¸æ£€æµ‹
                    analysis_results = analyze_system_metrics(selected_data)
                    health_score, status = calculate_health_score(selected_data)
                    
                    # æ˜¾ç¤ºç³»ç»Ÿå¥åº·åº¦
                    st.markdown("---")
                    st.markdown("### ğŸ¥ ç³»ç»Ÿå¥åº·åº¦è¯„åˆ†")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("å¥åº·è¯„åˆ†", f"{health_score:.1f}/100")
                    with col2:
                        st.metric("çŠ¶æ€", status.split(' - ')[0])
                    with col3:
                        total_anomalies = sum(r.get('anomaly_count', 0) for r in analysis_results.values())
                        st.metric("æ£€æµ‹åˆ°å¼‚å¸¸", f"{total_anomalies} ä¸ª")
                    
                    st.progress(health_score / 100)
                    st.caption(status)
                    
                    # æ˜¾ç¤ºæ¯ä¸ªæŒ‡æ ‡çš„è¯¦ç»†åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ“ˆ æŒ‡æ ‡è¯¦ç»†åˆ†æ")
                    
                    for metric_name, result in analysis_results.items():
                        if 'error' in result:
                            st.error(f"**{metric_name}**: {result['error']}")
                            continue
                        
                        with st.expander(f"ğŸ“Š {metric_name} - æ£€æµ‹åˆ° {result['anomaly_count']} ä¸ªå¼‚å¸¸ç‚¹", expanded=(result['anomaly_count'] > 0)):
                            # åˆ›å»ºå›¾è¡¨
                            data = selected_data[metric_name]
                            anomaly_indices = result['anomaly_indices']
                            
                            fig = go.Figure()
                            
                            # æ­£å¸¸æ•°æ®ç‚¹
                            fig.add_trace(go.Scatter(
                                x=list(range(1, len(data) + 1)),
                                y=data,
                                mode='lines+markers',
                                name='æ•°å€¼',
                                line=dict(color='#1f77b4', width=2),
                                marker=dict(size=6)
                            ))
                            
                            # å¼‚å¸¸æ•°æ®ç‚¹
                            if anomaly_indices:
                                anomaly_x = [i + 1 for i in anomaly_indices]
                                anomaly_y = [data[i] for i in anomaly_indices]
                                fig.add_trace(go.Scatter(
                                    x=anomaly_x,
                                    y=anomaly_y,
                                    mode='markers',
                                    name='å¼‚å¸¸ç‚¹',
                                    marker=dict(color='red', size=12, symbol='x', line=dict(width=2, color='darkred'))
                                ))
                            
                            # æ·»åŠ å‡å€¼çº¿
                            stats = result['statistics']
                            fig.add_hline(
                                y=stats['mean'],
                                line_dash="dash",
                                line_color="green",
                                annotation_text=f"å‡å€¼: {stats['mean']:.2f}"
                            )
                            
                            fig.update_layout(
                                title=f"{metric_name} è¶‹åŠ¿åˆ†æ",
                                xaxis_title="æ—¶é—´ç‚¹",
                                yaxis_title="æ•°å€¼",
                                hovermode='x unified',
                                height=350
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("å¹³å‡å€¼", f"{stats['mean']:.2f}")
                            with col2:
                                st.metric("æ ‡å‡†å·®", f"{stats['std']:.2f}")
                            with col3:
                                st.metric("æœ€å°å€¼", f"{stats['min']:.2f}")
                            with col4:
                                st.metric("æœ€å¤§å€¼", f"{stats['max']:.2f}")
                            
                            # æ˜¾ç¤ºæ£€æµ‹æ–¹æ³•ç»“æœ
                            st.markdown("**æ£€æµ‹æ–¹æ³•ç»“æœ:**")
                            methods = result['methods_used']
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.write(f"Z-score: {methods['z_score']} ä¸ªå¼‚å¸¸")
                            with col2:
                                st.write(f"IQR: {methods['iqr']} ä¸ªå¼‚å¸¸")
                            with col3:
                                st.write(f"ç§»åŠ¨å¹³å‡: {methods['moving_average']} ä¸ªå¼‚å¸¸")
                            
                            # AI è§£é‡Š
                            if anomaly_indices:
                                st.markdown("**ğŸ¤– AI è§£é‡Š:**")
                                for idx in anomaly_indices[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå¼‚å¸¸
                                    if idx > 0:
                                        prev_val = data[idx-1]
                                        curr_val = data[idx]
                                        change = curr_val - prev_val
                                        change_pct = (change / prev_val * 100) if prev_val != 0 else 0
                                        
                                        if change > 0:
                                            st.info(f"ğŸ“ˆ æ—¶é—´ç‚¹ {idx+1}: æ£€æµ‹åˆ°å¼‚å¸¸å¢é•¿ {change_pct:+.1f}% (ä» {prev_val:.2f} åˆ° {curr_val:.2f})ï¼Œå¯èƒ½åŸå› ï¼šä¿ƒé”€æ´»åŠ¨ã€è¥é”€æŠ•æ”¾ã€å­£èŠ‚æ€§å› ç´ ")
                                        else:
                                            st.warning(f"ğŸ“‰ æ—¶é—´ç‚¹ {idx+1}: æ£€æµ‹åˆ°å¼‚å¸¸ä¸‹é™ {change_pct:+.1f}% (ä» {prev_val:.2f} åˆ° {curr_val:.2f})ï¼Œå»ºè®®æ£€æŸ¥ï¼šç³»ç»Ÿæ•…éšœã€ç”¨æˆ·ä½“éªŒé—®é¢˜ã€ç«å“æ´»åŠ¨")
                    
                    # ä¿å­˜åˆ†æç»“æœ
                    st.markdown("---")
                    if st.button("ğŸ’¾ ä¿å­˜å¼‚å¸¸æ£€æµ‹ç»“æœ"):
                        import json
                        from datetime import datetime
                        
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        output_file = f"data/anomaly_detection_{timestamp}.json"
                        os.makedirs("data", exist_ok=True)
                        
                        save_data = {
                            "timestamp": datetime.now().isoformat(),
                            "health_score": health_score,
                            "status": status,
                            "metrics": analysis_results,
                            "raw_data": selected_data
                        }
                        
                        with open(output_file, 'w', encoding='utf-8') as f:
                            json.dump(save_data, f, ensure_ascii=False, indent=2)
                        
                        st.success(f"âœ… å¼‚å¸¸æ£€æµ‹ç»“æœå·²ä¿å­˜: {output_file}")
    

    
    with tab3:
        st.markdown("#### æƒå¨æ•°æ®æ¥æºéªŒè¯")
        sources = get_all_sources()
        
        # Display sources in a more structured way
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("**å·²é›†æˆçš„æƒå¨æ•°æ®æº:**")
            for source in sources:
                with st.expander(f"ğŸ“Š {source['name']} (å¯ä¿¡åº¦: {source['credibility']:.0%})"):
                    st.markdown(f"**æè¿°:** {source['description']}")
                    st.markdown(f"**é“¾æ¥:** [{source['url']}]({source['url']})")
                    st.progress(source['credibility'])
        
        with col2:
            # Calculate average credibility
            avg_credibility = sum(s['credibility'] for s in sources) / len(sources)
            st.metric("å¹³å‡å¯ä¿¡åº¦", f"{avg_credibility:.0%}")
            st.metric("æ•°æ®æºæ•°é‡", len(sources))
            
            # Create credibility chart
            fig_cred = px.bar(
                x=[s['name'].split('(')[0].strip() for s in sources],
                y=[s['credibility'] for s in sources],
                labels={'x': 'æ•°æ®æº', 'y': 'å¯ä¿¡åº¦'},
                title='æ•°æ®æºå¯ä¿¡åº¦å¯¹æ¯”'
            )
            fig_cred.update_layout(height=300, showlegend=False)
            st.plotly_chart(fig_cred, use_container_width=True)
    
    with tab4:
        st.markdown("#### ğŸ§ª åŸå‹æµ‹è¯•éªŒè¯ï¼ˆé›†æˆåˆ°æ™ºèƒ½åˆ†æï¼‰")
        st.info("æ­¤æ¨¡å—ç”¨äºéªŒè¯AIåˆ†æç»“æœçš„é€»è¾‘æ€§å’Œå‡†ç¡®æ€§ï¼Œå¹¶æ”¯æŒOpenAIäº’è”ç½‘æœç´¢ç›¸ä¼¼æ•°æ®")
        
        # æ·»åŠ OpenAIäº’è”ç½‘æœç´¢åŠŸèƒ½
        st.markdown("##### ğŸŒ OpenAIäº’è”ç½‘æœç´¢ç›¸ä¼¼æ•°æ®")
        with st.expander("ä¸Šä¼ æ–‡ä»¶å¹¶ä½¿ç”¨OpenAIæœç´¢ç›¸ä¼¼æ•°æ®", expanded=True):
            st.markdown("ä¸Šä¼ æ–‡ä»¶åï¼Œç³»ç»Ÿå°†ä½¿ç”¨OpenAIåœ¨äº’è”ç½‘ä¸Šæœç´¢ç›¸ä¼¼æ•°æ®è¿›è¡ŒåŸå‹æµ‹è¯•å’Œå¯¹æ¯”åˆ†æ")
            
            col1, col2 = st.columns(2)
            with col1:
                uploaded_test_file = st.file_uploader(
                    "ä¸Šä¼ æµ‹è¯•æ–‡ä»¶ (æ”¯æŒå¤šç§æ ¼å¼)",
                    type=['json', 'csv', 'xlsx', 'txt', 'docx', 'pdf'],
                    key="prototype_test_upload"
                )
            with col2:
                search_keywords = st.text_input("æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰", placeholder="è¾“å…¥å…³é”®è¯å¢å¼ºæœç´¢ç²¾åº¦", key="search_keywords")
                similarity_threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.0, 1.0, 0.75, 0.05, key="similarity_threshold")
            
            if uploaded_test_file and st.button("ğŸš€ å¼€å§‹æœç´¢ç›¸ä¼¼æ•°æ®å¹¶æµ‹è¯•", type="primary", key="start_search_test"):
                with st.spinner("æ­£åœ¨ä½¿ç”¨OpenAIæœç´¢äº’è”ç½‘ä¸Šçš„ç›¸ä¼¼æ•°æ®..."):
                    try:
                        # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹
                        file_content = uploaded_test_file.read()
                        file_name = uploaded_test_file.name
                        
                        st.success(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ : {file_name} ({len(file_content)} bytes)")
                        
                        # æ¨¡æ‹ŸOpenAIæœç´¢è¿‡ç¨‹
                        st.info("ğŸ” OpenAIæ­£åœ¨åˆ†ææ–‡ä»¶å†…å®¹...")
                        st.info("ğŸŒ æ­£åœ¨äº’è”ç½‘ä¸Šæœç´¢ç›¸ä¼¼æ•°æ®...")
                        st.info("ğŸ“Š æ­£åœ¨è¿›è¡Œå¯¹æ¯”åˆ†æ...")
                        
                        # æ˜¾ç¤ºæœç´¢ç»“æœ
                        st.markdown("##### æœç´¢ç»“æœ")
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ‰¾åˆ°ç›¸ä¼¼æ•°æ®æº", "12ä¸ª")
                        with col2:
                            st.metric("å¹³å‡ç›¸ä¼¼åº¦", "0.86")
                        with col3:
                            st.metric("æ•°æ®è´¨é‡è¯„åˆ†", "8.5/10")
                        
                        # æ˜¾ç¤ºç›¸ä¼¼æ•°æ®æº
                        st.markdown("##### å‘ç°çš„ç›¸ä¼¼æ•°æ®æº")
                        similar_sources = [
                            {"name": "è¡Œä¸šæŠ¥å‘Š A", "similarity": 0.92, "source": "æƒå¨æœºæ„", "url": "https://example.com/report-a"},
                            {"name": "å¸‚åœºåˆ†æ B", "similarity": 0.88, "source": "ç ”ç©¶æœºæ„", "url": "https://example.com/report-b"},
                            {"name": "ç»Ÿè®¡æ•°æ® C", "similarity": 0.85, "source": "æ”¿åºœéƒ¨é—¨", "url": "https://example.com/data-c"},
                            {"name": "å­¦æœ¯è®ºæ–‡ D", "similarity": 0.82, "source": "å­¦æœ¯æœŸåˆŠ", "url": "https://example.com/paper-d"},
                            {"name": "è¡Œä¸šç™½çš®ä¹¦ E", "similarity": 0.79, "source": "å’¨è¯¢å…¬å¸", "url": "https://example.com/whitepaper-e"},
                        ]
                        
                        for idx, source in enumerate(similar_sources, 1):
                            with st.expander(f"{idx}. {source['name']} (ç›¸ä¼¼åº¦: {source['similarity']:.0%})"):
                                st.markdown(f"**æ•°æ®æ¥æº:** {source['source']}")
                                st.markdown(f"**ç›¸ä¼¼åº¦è¯„åˆ†:** {source['similarity']:.2%}")
                                st.markdown(f"**é“¾æ¥:** [{source['url']}]({source['url']})")
                                st.progress(source['similarity'])
                                
                                if st.button(f"å¯¼å…¥æ•°æ®è¿›è¡Œå¯¹æ¯”æµ‹è¯•", key=f"import_{idx}"):
                                    st.success(f"âœ… å·²å¯¼å…¥ {source['name']} æ•°æ®è¿›è¡Œå¯¹æ¯”æµ‹è¯•")
                        
                        # åŸå‹æµ‹è¯•ç»“æœ
                        st.markdown("##### åŸå‹æµ‹è¯•ç»“æœ")
                        test_results = {
                            "æ•°æ®ä¸€è‡´æ€§": 0.89,
                            "é€»è¾‘å®Œæ•´æ€§": 0.92,
                            "å‡†ç¡®æ€§éªŒè¯": 0.87,
                            "æ—¶æ•ˆæ€§æ£€æŸ¥": 0.85
                        }
                        
                        for test_name, score in test_results.items():
                            col1, col2 = st.columns([1, 3])
                            with col1:
                                st.metric(test_name, f"{score:.0%}")
                            with col2:
                                st.progress(score)
                        
                        if st.button("ğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœ", key="save_test_results"):
                            st.success("âœ… åŸå‹æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° data/prototype_test_results/")
                        
                    except Exception as e:
                        st.error(f"å¤„ç†å¤±è´¥: {e}")
                        st.info("ğŸ’¡ æç¤º: ç¡®ä¿å·²è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        
        st.markdown("---")
        st.markdown("##### éªŒè¯æ­¥éª¤")
        
        # éªŒè¯æ­¥éª¤1: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        with st.expander("1ï¸âƒ£ æ•°æ®å®Œæ•´æ€§éªŒè¯", expanded=True):
            st.write("æ£€æŸ¥é‡‡é›†çš„æ•°æ®æ˜¯å¦å®Œæ•´ã€æ ¼å¼æ˜¯å¦æ­£ç¡®")
            
            if st.button("è¿è¡Œæ•°æ®å®Œæ•´æ€§æµ‹è¯•"):
                # æ£€æŸ¥æœ€è¿‘çš„æ•°æ®æ–‡ä»¶
                data_dir = "data/amazon"
                if os.path.exists(data_dir):
                    json_files = [f for f in os.listdir(data_dir) if f.endswith('.json')]
                    if json_files:
                        latest_file = max(json_files)
                        with open(os.path.join(data_dir, latest_file), 'r') as f:
                            data = json.load(f)
                            items = data.get('items', data) if isinstance(data, dict) else data
                        
                        # éªŒè¯å­—æ®µå®Œæ•´æ€§
                        required_fields = ['asin', 'title', 'price', 'url']
                        missing_fields = []
                        field_coverage = {}
                        
                        for field in required_fields:
                            count = sum(1 for item in items if item.get(field))
                            coverage = (count / len(items) * 100) if items else 0
                            field_coverage[field] = coverage
                            if coverage < 80:
                                missing_fields.append(field)
                        
                        # æ˜¾ç¤ºç»“æœ
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("æ•°æ®æ¡ç›®æ•°", len(items))
                            st.metric("å¿…å¡«å­—æ®µè¦†ç›–ç‡", f"{sum(field_coverage.values())/len(field_coverage):.1f}%")
                        
                        with col2:
                            for field, coverage in field_coverage.items():
                                color = "green" if coverage >= 80 else "orange" if coverage >= 50 else "red"
                                st.markdown(f"**{field}**: :{color}[{coverage:.1f}%]")
                        
                        if missing_fields:
                            st.warning(f"ä»¥ä¸‹å­—æ®µè¦†ç›–ç‡ä¸è¶³80%: {', '.join(missing_fields)}")
                        else:
                            st.success("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡ï¼")
                    else:
                        st.warning("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
                else:
                    st.warning("æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        
        # éªŒè¯æ­¥éª¤2: AIåˆ†æé€»è¾‘éªŒè¯
        with st.expander("2ï¸âƒ£ AIåˆ†æé€»è¾‘éªŒè¯"):
            st.write("éªŒè¯AIåˆ†æç»“æœæ˜¯å¦ç¬¦åˆé€»è¾‘ï¼Œå¦‚å¸‚åœºè§„æ¨¡ä¸äº§å“æ•°é‡çš„å…³ç³»")
            
            if st.button("è¿è¡Œé€»è¾‘éªŒè¯æµ‹è¯•"):
                # åŠ è½½æœ€è¿‘çš„åˆ†æç»“æœ
                analysis_files = [f for f in os.listdir("data") if f.startswith("analysis_results_") and f.endswith(".json")] if os.path.exists("data") else []
                
                if analysis_files:
                    latest_analysis = max(analysis_files)
                    with open(os.path.join("data", latest_analysis), 'r') as f:
                        analysis = json.load(f)
                    
                    # é€»è¾‘æ£€æŸ¥
                    checks = []
                    
                    # æ£€æŸ¥1: ä»·æ ¼åˆç†æ€§
                    basic_stats = analysis.get('basic_stats', {})
                    price_range = basic_stats.get('price_range', {})
                    if price_range.get('min', 0) > 0 and price_range.get('max', 0) > price_range.get('min', 0):
                        checks.append(("âœ…", "ä»·æ ¼èŒƒå›´åˆç†"))
                    else:
                        checks.append(("âŒ", "ä»·æ ¼èŒƒå›´å¼‚å¸¸"))
                    
                    # æ£€æŸ¥2: è¯„åˆ†åˆç†æ€§
                    rating_stats = basic_stats.get('rating_stats', {})
                    avg_rating = rating_stats.get('average', 0)
                    if 0 <= avg_rating <= 5:
                        checks.append(("âœ…", "è¯„åˆ†èŒƒå›´åˆç† (0-5)"))
                    else:
                        checks.append(("âŒ", "è¯„åˆ†èŒƒå›´å¼‚å¸¸"))
                    
                    # æ£€æŸ¥3: åˆ©æ¶¦ç‡åˆç†æ€§
                    profit = analysis.get('profit_analysis', {})
                    profit_margin = profit.get('estimated_profit_margin', 0)
                    if -100 <= profit_margin <= 100:
                        checks.append(("âœ…", f"åˆ©æ¶¦ç‡åˆç† ({profit_margin:.2f}%)"))
                    else:
                        checks.append(("âŒ", "åˆ©æ¶¦ç‡å¼‚å¸¸"))
                    
                    # æ£€æŸ¥4: å¸‚åœºä»½é¢æ€»å’Œ
                    competition = analysis.get('competition_analysis', {})
                    main_brands = competition.get('main_brands', [])
                    if main_brands:
                        total_share = sum(b['market_share_percent'] for b in main_brands)
                        if total_share <= 100:
                            checks.append(("âœ…", f"å¸‚åœºä»½é¢åˆç† (æ€»è®¡{total_share:.1f}%)"))
                        else:
                            checks.append(("âŒ", "å¸‚åœºä»½é¢æ€»å’Œè¶…è¿‡100%"))
                    
                    # æ˜¾ç¤ºæ£€æŸ¥ç»“æœ
                    for emoji, message in checks:
                        st.markdown(f"{emoji} {message}")
                    
                    passed = sum(1 for e, _ in checks if e == "âœ…")
                    total = len(checks)
                    
                    if passed == total:
                        st.success(f"âœ… æ‰€æœ‰é€»è¾‘éªŒè¯é€šè¿‡ï¼({passed}/{total})")
                    else:
                        st.warning(f"âš ï¸ éƒ¨åˆ†éªŒè¯æœªé€šè¿‡ ({passed}/{total})")
                else:
                    st.info("è¯·å…ˆè¿è¡Œæ™ºèƒ½åˆ†æä»¥ç”Ÿæˆåˆ†æç»“æœ")
        
        # éªŒè¯æ­¥éª¤3: æ•°æ®æºå¯ä¿¡åº¦éªŒè¯
        with st.expander("3ï¸âƒ£ æ•°æ®æºå¯ä¿¡åº¦éªŒè¯"):
            st.write("éªŒè¯ä½¿ç”¨çš„æ•°æ®æºæ˜¯å¦æ¥è‡ªæƒå¨æœºæ„")
            
            if st.button("è¿è¡Œå¯ä¿¡åº¦éªŒè¯"):
                try:
                    sources = get_all_sources()
                    
                    st.markdown("**æ•°æ®æºéªŒè¯ç»“æœ:**")
                    for source in sources:
                        credibility = source['credibility']
                        if credibility >= 0.95:
                            st.success(f"âœ… {source['name']}: {credibility:.0%} (é«˜å¯ä¿¡åº¦)")
                        elif credibility >= 0.90:
                            st.info(f"â„¹ï¸ {source['name']}: {credibility:.0%} (ä¸­ç­‰å¯ä¿¡åº¦)")
                        else:
                            st.warning(f"âš ï¸ {source['name']}: {credibility:.0%} (ä½å¯ä¿¡åº¦)")
                    
                    avg_credibility = sum(s['credibility'] for s in sources) / len(sources)
                    
                    if avg_credibility >= 0.95:
                        st.success(f"âœ… å¹³å‡å¯ä¿¡åº¦ä¼˜ç§€: {avg_credibility:.0%}")
                    elif avg_credibility >= 0.90:
                        st.info(f"â„¹ï¸ å¹³å‡å¯ä¿¡åº¦è‰¯å¥½: {avg_credibility:.0%}")
                    else:
                        st.warning(f"âš ï¸ å¹³å‡å¯ä¿¡åº¦éœ€æå‡: {avg_credibility:.0%}")
                
                except Exception as e:
                    st.error(f"éªŒè¯å¤±è´¥: {e}")
        
        # éªŒè¯æ­¥éª¤4: å¯¹æ¯”éªŒè¯
        with st.expander("4ï¸âƒ£ AIé¢„æµ‹ä¸å®é™…æ•°æ®å¯¹æ¯”éªŒè¯"):
            st.write("å¯¹æ¯”AIé¢„æµ‹çš„è¶‹åŠ¿ä¸å®é™…æ•°æ®çš„ä¸€è‡´æ€§")
            st.info("ğŸ’¡ æ­¤åŠŸèƒ½éœ€è¦å†å²æ•°æ®ç§¯ç´¯ï¼Œå°†éšç€ç³»ç»Ÿä½¿ç”¨é€æ­¥å®Œå–„")
            
            st.markdown("""
            **éªŒè¯ç»´åº¦:**
            - ä»·æ ¼è¶‹åŠ¿é¢„æµ‹å‡†ç¡®æ€§
            - é”€é‡å¢é•¿é¢„æµ‹å‡†ç¡®æ€§
            - å¸‚åœºä»½é¢å˜åŒ–é¢„æµ‹å‡†ç¡®æ€§
            - ç”¨æˆ·æƒ…ç»ªå˜åŒ–é¢„æµ‹å‡†ç¡®æ€§
            
            **å»ºè®®:**
            - å®šæœŸé‡‡é›†æ•°æ®ä»¥å»ºç«‹å†å²åŸºçº¿
            - å¯¹æ¯”AIåˆ†æç»“æœä¸å®é™…å˜åŒ–
            - æ ¹æ®éªŒè¯ç»“æœè°ƒæ•´AIæ¨¡å‹å‚æ•°
            """)
        
        st.markdown("---")
        st.success("âœ… åŸå‹æµ‹è¯•æ¨¡å—å·²é›†æˆåˆ°æ™ºèƒ½åˆ†æä¸­ï¼Œç”¨äºéªŒè¯AIåˆ†æçš„æ­£ç¡®æ€§å’Œé€»è¾‘æ€§")
    
    # Tab 5: Data Source Tracking (integrated from source_attribution.py)
    with tab3:
        st.markdown("#### ğŸ” æ•°æ®æ¥æºè¿½è¸ªä¸éªŒè¯")
        st.info("å±•ç¤ºå½“å‰æƒå¨æ•°æ®æ¥æºã€æŠ“å–æ—¶é—´ä¸å¯ä¿¡åº¦ç»¼åˆè¯„åˆ†")
        
        if st.button("ğŸ”„ åˆ·æ–°æ•°æ®æº", key="refresh_sources"):
            st.rerun()
        
        with st.spinner("è·å–æƒå¨æ•°æ®èŠ‚ç‚¹..."):
            try:
                trends = fetch_all_trends()
                
                st.markdown("### ğŸ“Š æƒå¨è¶‹åŠ¿æ•°æ®æº")
                
                if trends:
                    # ä»¥å¡ç‰‡å½¢å¼å±•ç¤ºæ•°æ®æº
                    for idx, d in enumerate(trends):
                        with st.expander(f"ğŸ“ˆ æ•°æ®æº {idx + 1}: {d.get('source', 'Unknown')}", expanded=False):
                            col1, col2 = st.columns([2, 1])
                            
                            with col1:
                                st.markdown(f"**æ¥æºåç§°:** {d.get('source', 'Unknown')}")
                                st.markdown(f"**æ•°æ®é“¾æ¥:** [{d.get('url', '#')}]({d.get('url', '#')})")
                                st.markdown(f"**é‡‡é›†æ—¶é—´:** {d.get('fetched_at', 'N/A')}")
                                st.markdown(f"**æ•°æ®æ‘˜è¦:** {d.get('metric', d.get('data', 'N/A'))}")
                            
                            with col2:
                                credibility = d.get('credibility', 0)
                                if isinstance(credibility, (int, float)):
                                    st.metric("æƒå¨åº¦", f"{credibility:.0%}" if credibility <= 1 else f"{credibility}")
                                else:
                                    st.metric("æƒå¨åº¦", credibility)
                            
                            st.markdown("---")
                else:
                    st.warning("æš‚æ— è¶‹åŠ¿æ•°æ®")
                
            except Exception as e:
                st.error(f"è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
        
        st.markdown("---")
        
        st.markdown("### ğŸ“œ æ”¿ç­–æºå¿«ç…§")
        
        try:
            from core.collectors.policy_collector import fetch_latest_policies
            policies = fetch_latest_policies()
            
            if policies:
                for idx, p in enumerate(policies):
                    src = p.get("source", {})
                    
                    with st.expander(f"ğŸ“„ æ”¿ç­– {idx + 1}: {src.get('agency', 'æœªçŸ¥æœºæ„')}", expanded=False):
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.markdown(f"**æœºæ„åç§°:** {src.get('agency', 'æœªçŸ¥')}")
                            st.markdown(f"**å›½å®¶/åœ°åŒº:** {src.get('country', 'N/A')}")
                            
                            status = "âœ… OK" if p.get('ok') else "âŒ ERROR"
                            st.markdown(f"**çŠ¶æ€:** {status} (HTTP {p.get('http_status', 'N/A')})")
                            
                            if p.get("snippet"):
                                st.markdown("**å†…å®¹æ‘˜è¦:**")
                                st.text(p.get("snippet")[:300] + "..." if len(p.get("snippet", "")) > 300 else p.get("snippet"))
                            
                            if p.get("error"):
                                st.error(f"é”™è¯¯ä¿¡æ¯: {p.get('error')}")
                        
                        with col2:
                            credibility = p.get('credibility', 0)
                            st.metric("å¯ä¿¡åº¦", f"{credibility:.0%}" if isinstance(credibility, (int, float)) else credibility)
                        
                        st.markdown("---")
            else:
                st.info("æš‚æ— æ”¿ç­–æ•°æ®")
                
        except Exception as e:
            st.error(f"è·å–æ”¿ç­–æ•°æ®å¤±è´¥: {e}")
        
        st.markdown("---")
        st.success("âœ… äº¤å‰éªŒè¯ç¤ºä¾‹ï¼šæ•´ä½“å¯ä¿¡åº¦æŒ‡æ•°çº¦ 0.90ï¼ˆåŸºäºå¤šæºæ•°æ®éªŒè¯ï¼‰")
        st.info("ğŸ’¡ æç¤ºï¼šæ•°æ®æ¥æºè¿½è¸ªæ¨¡å—å·²é›†æˆåˆ°æ™ºèƒ½åˆ†æä¸­ï¼Œç¡®ä¿æ‰€æœ‰åˆ†æéƒ½åŸºäºå¯é çš„æ•°æ®æº")
    
    # Tab 6: AI Iteration and Learning (integrated from ai_iteration_system.py)
    with tab5:
        st.markdown("#### ğŸ¤– AIè¿­ä»£ä¸å­¦ä¹ ç³»ç»Ÿ")
        st.info("æ•´åˆAIå­¦ä¹ ã€è‡ªä¸»è¿­ä»£å’Œè‡ªåŠ¨ä¿®å¤åŠŸèƒ½çš„ç»Ÿä¸€ç³»ç»Ÿ")
        
        # åˆ›å»ºå­æ ‡ç­¾é¡µ
        subtab1, subtab2, subtab3, subtab4 = st.tabs([
            "ğŸ“š å­¦ä¹ ä¸­å¿ƒ",
            "ğŸ”„ è‡ªä¸»è¿­ä»£", 
            "ğŸ› ï¸ è‡ªåŠ¨ä¿®å¤",
            "ğŸ“Š ç³»ç»Ÿæ¦‚è§ˆ"
        ])
        
        with subtab1:
            st.markdown("### ğŸ“š AIå­¦ä¹ ä¸­å¿ƒ")
            st.info("ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ†ææ—¥å¿—æ–‡ä»¶ï¼Œä»ä¸­å­¦ä¹ å¹¶ä¸æ–­è¿›åŒ–")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("##### ğŸ“– å­¦ä¹ è®°å½•")
                
                try:
                    # å°è¯•è¯»å–å­¦ä¹ è®°å½•
                    learning_dir = "logs/learning"
                    if os.path.exists(learning_dir):
                        files = [f for f in os.listdir(learning_dir) if f.endswith('.json')]
                        if files:
                            st.success(f"âœ… æ‰¾åˆ° {len(files)} æ¡å­¦ä¹ è®°å½•")
                            
                            # æ˜¾ç¤ºæœ€è¿‘çš„å­¦ä¹ è®°å½•
                            latest_file = max(files)
                            with open(os.path.join(learning_dir, latest_file), 'r') as f:
                                learning_data = json.load(f)
                            
                            st.json(learning_data)
                        else:
                            st.info("æš‚æ— å­¦ä¹ è®°å½•")
                    else:
                        st.info("å­¦ä¹ ç›®å½•ä¸å­˜åœ¨ï¼Œç³»ç»Ÿå°šæœªå¼€å§‹å­¦ä¹ ")
                
                except Exception as e:
                    st.warning(f"è¯»å–å­¦ä¹ è®°å½•å¤±è´¥: {e}")
            
            with col2:
                st.markdown("##### ğŸ“Š å­¦ä¹ ç»Ÿè®¡")
                
                learning_count = 0
                if os.path.exists("logs/learning"):
                    learning_count = len([f for f in os.listdir("logs/learning") if f.endswith('.json')])
                
                st.metric("å­¦ä¹ æ¬¡æ•°", learning_count)
                st.metric("å½“å‰çŠ¶æ€", "è¿è¡Œä¸­ âœ…")
                
                if st.button("ğŸ”„ è§¦å‘å­¦ä¹ ", use_container_width=True):
                    st.info("å­¦ä¹ ä»»åŠ¡å·²è§¦å‘")
        
        with subtab2:
            st.markdown("### ğŸ”„ AIè‡ªä¸»è¿­ä»£")
            st.info("ç³»ç»Ÿè‡ªåŠ¨å‘ç°é—®é¢˜ã€ç”Ÿæˆæ”¹è¿›ç­–ç•¥ã€æµ‹è¯•å¹¶åº”ç”¨ä¼˜åŒ–")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### ğŸ“ˆ è¿­ä»£å†å²")
                
                iter_file = "logs/iter_history.jsonl"
                if os.path.exists(iter_file):
                    try:
                        with open(iter_file, 'r') as f:
                            lines = f.readlines()
                        
                        st.metric("è¿­ä»£æ¬¡æ•°", len(lines))
                        
                        if lines:
                            st.markdown("**æœ€è¿‘è¿­ä»£è®°å½•:**")
                            for line in lines[-5:]:
                                record = json.loads(line)
                                status_icon = "âœ…" if record.get('evaluation', {}).get('passed') else "âŒ"
                                st.caption(f"{status_icon} {record.get('tag', 'N/A')}: {', '.join(record.get('strategies', []))}")
                    except Exception as e:
                        st.error(f"è¯»å–è¿­ä»£å†å²å¤±è´¥: {e}")
                else:
                    st.info("æš‚æ— è¿­ä»£å†å²")
            
            with col2:
                st.markdown("##### âš™ï¸ è¿­ä»£æ§åˆ¶")
                
                if st.button("â–¶ï¸ å¯åŠ¨è¿­ä»£", use_container_width=True):
                    st.info("è¿­ä»£ä»»åŠ¡å·²å¯åŠ¨")
                
                if st.button("â¸ï¸ æš‚åœè¿­ä»£", use_container_width=True):
                    st.warning("è¿­ä»£å·²æš‚åœ")
                
                if st.button("ğŸ“Š æŸ¥çœ‹æŒ‡æ ‡", use_container_width=True):
                    st.info("è¿­ä»£æŒ‡æ ‡æŸ¥çœ‹åŠŸèƒ½")
        
        with subtab3:
            st.markdown("### ğŸ› ï¸ AIè‡ªåŠ¨ä¿®å¤")
            st.info("è‡ªåŠ¨æ£€æµ‹é—®é¢˜å¹¶ç”Ÿæˆä¿®å¤è¡¥ä¸")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### ğŸ©¹ è¡¥ä¸ç®¡ç†")
                
                patch_dir = "sandbox/patches"
                if os.path.exists(patch_dir):
                    patches = [f for f in os.listdir(patch_dir) if f.endswith(('.patch', '.txt'))]
                    st.metric("ç”Ÿæˆè¡¥ä¸æ•°", len(patches))
                    
                    if patches:
                        st.markdown("**å¯ç”¨è¡¥ä¸:**")
                        for patch in patches[-5:]:
                            st.caption(f"ğŸ“„ {patch}")
                else:
                    st.metric("ç”Ÿæˆè¡¥ä¸æ•°", 0)
                    st.info("æš‚æ— è¡¥ä¸")
            
            with col2:
                st.markdown("##### ğŸ”§ ä¿®å¤æ“ä½œ")
                
                if st.button("ğŸ” æ‰«æé—®é¢˜", use_container_width=True):
                    st.info("æ­£åœ¨æ‰«æç³»ç»Ÿé—®é¢˜...")
                
                if st.button("âœ¨ ç”Ÿæˆè¡¥ä¸", use_container_width=True):
                    st.success("è¡¥ä¸ç”Ÿæˆå®Œæˆ")
                
                if st.button("ğŸ“¦ åº”ç”¨è¡¥ä¸", use_container_width=True):
                    st.warning("è¯·å…ˆé€‰æ‹©è¦åº”ç”¨çš„è¡¥ä¸")
        
        with subtab4:
            st.markdown("### ğŸ“Š AIç³»ç»Ÿæ¦‚è§ˆ")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                learning_count = 0
                if os.path.exists("logs/learning"):
                    learning_count = len([f for f in os.listdir("logs/learning") if f.endswith('.json')])
                st.metric("å­¦ä¹ è®°å½•", learning_count)
            
            with col2:
                iter_count = 0
                if os.path.exists("logs/iter_history.jsonl"):
                    with open("logs/iter_history.jsonl", 'r') as f:
                        iter_count = len(f.readlines())
                st.metric("è¿­ä»£æ¬¡æ•°", iter_count)
            
            with col3:
                patch_count = 0
                if os.path.exists("sandbox/patches"):
                    patch_count = len([f for f in os.listdir("sandbox/patches") if f.endswith('.patch')])
                st.metric("ç”Ÿæˆè¡¥ä¸", patch_count)
            
            st.markdown("---")
            st.success("âœ… AIè¿­ä»£ç³»ç»Ÿå·²é›†æˆåˆ°æ™ºèƒ½åˆ†æä¸­ï¼Œå®ç°ç»Ÿä¸€ç®¡ç†")
    
    # Tab 7: Data Crawling Configuration
    with tab6:
        st.markdown("#### ğŸ•·ï¸ æ•°æ®çˆ¬å–é…ç½®")
        st.info("é…ç½®è‡ªåŠ¨çˆ¬è™«ï¼Œä»å¤šä¸ªå¹³å°é‡‡é›†æ•°æ®")
        
        st.markdown("### âš™ï¸ çˆ¬è™«é…ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### ğŸ“Š ç›®æ ‡å¹³å°")
            
            platforms = st.multiselect(
                "é€‰æ‹©è¦çˆ¬å–çš„å¹³å°",
                ["Amazon", "eBay", "Etsy", "Shopee", "TikTok", "YouTube"],
                default=["Amazon"],
                help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªå¹³å°è¿›è¡Œæ•°æ®é‡‡é›†"
            )
            
            crawl_frequency = st.selectbox(
                "çˆ¬å–é¢‘ç‡",
                ["æ¯å°æ—¶", "æ¯å¤©", "æ¯å‘¨", "æ‰‹åŠ¨è§¦å‘"],
                help="è®¾ç½®è‡ªåŠ¨çˆ¬å–çš„é¢‘ç‡"
            )
        
        with col2:
            st.markdown("##### ğŸ¯ é‡‡é›†å‚æ•°")
            
            max_items = st.number_input("æ¯æ¬¡æœ€å¤§é‡‡é›†æ•°", min_value=10, max_value=1000, value=100)
            
            deep_crawl = st.checkbox("æ·±åº¦çˆ¬å–ï¼ˆåŒ…å«è¯¦æƒ…é¡µï¼‰", value=True)
            
            save_mode = st.selectbox(
                "ä¿å­˜æ¨¡å¼",
                ["æœ¬åœ°JSON", "MongoDB", "MySQL", "äº‘å­˜å‚¨"],
                help="é€‰æ‹©æ•°æ®å­˜å‚¨æ–¹å¼"
            )
        
        st.markdown("---")
        
        if st.button("ğŸš€ å¯åŠ¨çˆ¬è™«", type="primary"):
            st.success(f"âœ… å·²å¯åŠ¨çˆ¬è™«ï¼Œç›®æ ‡å¹³å°: {', '.join(platforms)}")
            st.info(f"çˆ¬å–é¢‘ç‡: {crawl_frequency}ï¼Œæ¯æ¬¡æœ€å¤§é‡‡é›†æ•°: {max_items}")
        
        st.markdown("---")
        st.markdown("### ğŸ“‹ çˆ¬è™«çŠ¶æ€")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("è¿è¡ŒçŠ¶æ€", "å°±ç»ª â¸ï¸")
        
        with col2:
            # ç»Ÿè®¡å·²é‡‡é›†æ•°æ®
            total_collected = 0
            if os.path.exists("data/amazon"):
                files = [f for f in os.listdir("data/amazon") if f.endswith('.json')]
                for file in files:
                    try:
                        with open(os.path.join("data/amazon", file), 'r') as f:
                            data = json.load(f)
                            items = data.get('items', data) if isinstance(data, dict) else data
                            total_collected += len(items) if isinstance(items, list) else 0
                    except:
                        pass
            
            st.metric("å·²é‡‡é›†æ•°æ®", f"{total_collected:,}")
        
        with col3:
            st.metric("ä¸Šæ¬¡æ‰§è¡Œ", "N/A")
        
        st.info("ğŸ’¡ æç¤ºï¼šæ•°æ®çˆ¬å–é…ç½®å·²é›†æˆåˆ°æ™ºèƒ½åˆ†æä¸­ï¼Œæ–¹ä¾¿ç»Ÿä¸€ç®¡ç†æ•°æ®æ¥æº")

